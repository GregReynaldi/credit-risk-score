{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Network Models\n",
        "\n",
        "This notebook trains and evaluates deep learning models for credit risk prediction.\n",
        "\n",
        "**Purpose**: Build advanced neural network models and create a stacked ensemble that combines multiple algorithms.\n",
        "\n",
        "**Models Trained**:\n",
        "1. **Pure TabNet**: Attention-based neural network designed for tabular data\n",
        "2. **TabNet + Tokenizer**: TabNet with feature tokenization for better representation\n",
        "3. **Deep & Cross Network (DCN)**: Combines cross layers and deep layers for feature interactions\n",
        "4. **Residual Neural Network**: Deep network with residual connections\n",
        "5. **Multi-Scale Ensemble**: Combines all models plus gradient boosting models via meta-learner\n",
        "\n",
        "**Key Techniques**:\n",
        "- **Focal Loss**: Handles class imbalance by focusing on hard examples\n",
        "- **Stacking**: Meta-learner combines predictions from multiple base models\n",
        "- **Class Weighting**: Adjusts model focus on minority class (bad loans)\n",
        "\n",
        "**Output**: Trained models and performance metrics saved to models/ and artifacts/03_2_neural_network_images/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score, f1_score,\n",
        "    precision_score, recall_score, precision_recall_curve,\n",
        "    confusion_matrix, classification_report, roc_curve, auc\n",
        ")\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "ROOT = os.path.abspath(os.getcwd())\n",
        "PROJECT_ROOT = os.path.abspath(os.path.join(ROOT, '..'))\n",
        "\n",
        "MODELS_DIR = os.path.join(PROJECT_ROOT, 'models')\n",
        "DATASET_DIR = os.path.join(PROJECT_ROOT, 'dataset')\n",
        "ARTIFACTS_DIR = os.path.join(PROJECT_ROOT, 'artifacts')\n",
        "\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.join(ARTIFACTS_DIR, '03_2_neural_network_images'), exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPRODUCIBILITY CONFIGURED\n",
            "All random seeds set to 42\n",
            "TensorFlow deterministic operations enabled\n",
            "PyTorch seeds configured\n",
            "Results will be consistent across runs\n"
          ]
        }
      ],
      "source": [
        "# REPRODUCIBILITY SETUP: Set all random seeds for consistent results\n",
        "# IMPORTANT: This ensures that every time you run this notebook, you get the\n",
        "# same results. Without this, neural networks will produce different results\n",
        "# each time due to random weight initialization and training randomness.\n",
        "\n",
        "import random\n",
        "\n",
        "# Set seed for Python's built-in random module\n",
        "random.seed(42)\n",
        "\n",
        "# Set seed for NumPy (used for array operations)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set seed for TensorFlow/Keras (neural network training)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Set seed for PyTorch (used by TabNet)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)  # For GPU if available\n",
        "torch.cuda.manual_seed_all(42)  # For multi-GPU if available\n",
        "\n",
        "# Additional TensorFlow settings for full reproducibility\n",
        "# These ensure deterministic operations (may be slower but reproducible)\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "\n",
        "# Set environment variable for TensorFlow determinism\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "print('REPRODUCIBILITY CONFIGURED')\n",
        "print('All random seeds set to 42')\n",
        "print('TensorFlow deterministic operations enabled')\n",
        "print('PyTorch seeds configured')\n",
        "print('Results will be consistent across runs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: (26064, 17), Test set: (6517, 17)\n"
          ]
        }
      ],
      "source": [
        "X_train_frame = pd.read_pickle(os.path.join(DATASET_DIR, 'X_train.pkl'))\n",
        "y_train_series = pd.read_pickle(os.path.join(DATASET_DIR, 'y_train.pkl'))\n",
        "X_test_frame = pd.read_pickle(os.path.join(DATASET_DIR, 'X_test.pkl'))\n",
        "y_test_series = pd.read_pickle(os.path.join(DATASET_DIR, 'y_test.pkl'))\n",
        "\n",
        "if isinstance(y_train_series, pd.DataFrame):\n",
        "    y_train_series = y_train_series.iloc[:, 0]\n",
        "if isinstance(y_test_series, pd.DataFrame):\n",
        "    y_test_series = y_test_series.iloc[:, 0]\n",
        "\n",
        "feature_names = list(X_train_frame.columns)\n",
        "\n",
        "X_train = X_train_frame.values\n",
        "X_test = X_test_frame.values\n",
        "y_train = y_train_series.values\n",
        "y_test = y_test_series.values\n",
        "\n",
        "print(f'Training set: {X_train.shape}, Test set: {X_test.shape}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive class ratio: 0.2182\n",
            "Class weight ratio: 3.58\n"
          ]
        }
      ],
      "source": [
        "pos_ratio = (y_train == 1).mean()\n",
        "neg_ratio = 1 - pos_ratio\n",
        "scale_pos_weight = neg_ratio / (pos_ratio + 1e-9)\n",
        "\n",
        "print(f'Positive class ratio: {pos_ratio:.4f}')\n",
        "print(f'Class weight ratio: {scale_pos_weight:.2f}')\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Focal Loss Definition\n",
        "\n",
        "**Purpose**: Define a custom loss function that handles class imbalance better than standard cross-entropy.\n",
        "\n",
        "**What is Focal Loss?**\n",
        "- Standard cross-entropy treats all examples equally\n",
        "- Focal loss down-weights easy examples and focuses on hard-to-classify examples\n",
        "- This is especially useful for imbalanced datasets (we have ~78% good loans, ~22% bad loans)\n",
        "\n",
        "**How it works**:\n",
        "- **Alpha (α)**: Balances positive/negative class importance\n",
        "- **Gamma (γ)**: Controls how much to focus on hard examples (higher = more focus)\n",
        "- Hard examples (misclassified) get higher weight, easy examples get lower weight\n",
        "\n",
        "**Why use it**: Helps the model learn better from the minority class (bad loans) without needing resampling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOCAL LOSS CONFIGURED\n",
            "Alpha (class balance): 0.25 (gives more weight to minority class)\n",
            "Gamma (focus parameter): 2.0 (focuses on hard examples)\n",
            "Focal loss ready to use in neural network training\n"
          ]
        }
      ],
      "source": [
        "# Configure Focal Loss Parameters\n",
        "# These values are commonly used and work well for imbalanced binary classification\n",
        "focal_alpha = 0.25  # Weight for positive class (bad loans) - balances class importance\n",
        "focal_gamma = 2.0   # Focusing parameter - higher values focus more on hard examples\n",
        "\n",
        "def binary_focal_loss(alpha=0.25, gamma=2.0):\n",
        "    \"\"\"\n",
        "    Focal Loss for Binary Classification with Imbalanced Data.\n",
        "    \n",
        "    This loss function helps neural networks learn better from imbalanced datasets by:\n",
        "    1. Balancing class importance (alpha parameter)\n",
        "    2. Focusing on hard-to-classify examples (gamma parameter)\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    alpha : float\n",
        "        Class balancing weight for positive examples (bad loans)\n",
        "        - 0.25 means positive class gets 25% weight, negative gets 75%\n",
        "        - Helps balance the impact of minority class\n",
        "    \n",
        "    gamma : float\n",
        "        Focusing parameter that down-weights easy examples\n",
        "        - Higher gamma (e.g., 2.0) = more focus on hard examples\n",
        "        - Easy examples (high confidence, correct predictions) get lower weight\n",
        "        - Hard examples (low confidence, wrong predictions) get higher weight\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    Callable\n",
        "        Keras-compatible loss function that can be used in model.compile()\n",
        "    \n",
        "    How it works:\n",
        "    - Computes standard cross-entropy loss\n",
        "    - Applies alpha weight to balance classes\n",
        "    - Applies focal weight (1 - probability)^gamma to focus on hard examples\n",
        "    - Easy examples (high probability of correct class) get down-weighted\n",
        "    - Hard examples (low probability) get up-weighted\n",
        "    \"\"\"\n",
        "    alpha_tensor = tf.constant(alpha, dtype=tf.float32)\n",
        "    gamma_tensor = tf.constant(gamma, dtype=tf.float32)\n",
        "\n",
        "    def loss(y_true, y_pred):\n",
        "        # Convert inputs to proper format\n",
        "        y_true_cast = tf.cast(tf.reshape(y_true, (-1, 1)), tf.float32)\n",
        "        y_pred_cast = tf.cast(tf.reshape(y_pred, (-1, 1)), tf.float32)\n",
        "        # Clip predictions to avoid log(0) errors\n",
        "        y_pred_clipped = tf.clip_by_value(y_pred_cast, 1e-7, 1.0 - 1e-7)\n",
        "\n",
        "        # Calculate probability of true class\n",
        "        true_class_prob = y_true_cast * y_pred_clipped + (1.0 - y_true_cast) * (1.0 - y_pred_clipped)\n",
        "        \n",
        "        # Standard cross-entropy loss\n",
        "        cross_entropy = -(y_true_cast * tf.math.log(y_pred_clipped) +\n",
        "                          (1.0 - y_true_cast) * tf.math.log(1.0 - y_pred_clipped))\n",
        "\n",
        "        # Alpha weight: Balance positive vs negative class\n",
        "        alpha_weight = y_true_cast * alpha_tensor + (1.0 - y_true_cast) * (1.0 - alpha_tensor)\n",
        "        \n",
        "        # Focal weight: Focus on hard examples (low probability of correct class)\n",
        "        # (1 - probability)^gamma: Higher gamma = more focus on hard examples\n",
        "        focal_weight = tf.pow(1.0 - true_class_prob, gamma_tensor)\n",
        "\n",
        "        # Combine: alpha_weight balances classes, focal_weight focuses on hard examples\n",
        "        focal_loss_value = alpha_weight * focal_weight * cross_entropy\n",
        "        return tf.reduce_mean(focal_loss_value)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Create the focal loss function with our parameters\n",
        "focal_loss = binary_focal_loss(alpha=focal_alpha, gamma=focal_gamma)\n",
        "\n",
        "print('FOCAL LOSS CONFIGURED')\n",
        "print(f'Alpha (class balance): {focal_alpha} (gives more weight to minority class)')\n",
        "print(f'Gamma (focus parameter): {focal_gamma} (focuses on hard examples)')\n",
        "print('Focal loss ready to use in neural network training')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 1: Pure TabNet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 42 with best_epoch = 27 and best_train_auc = 0.92699\n",
            "Pure TabNet training completed\n"
          ]
        }
      ],
      "source": [
        "# Set class weights to handle imbalanced data\n",
        "# Weight for class 1 (bad loans) is higher to make model focus on minority class\n",
        "class_weights = {0: 1.0, 1: neg_ratio / pos_ratio}\n",
        "\n",
        "# TabNet: Attention-based neural network designed specifically for tabular data\n",
        "# n_d=64, n_a=64: Dimension of decision and attention embeddings (controls model capacity)\n",
        "# n_steps=5: Number of sequential attention steps (more steps = more complex feature interactions)\n",
        "# gamma=1.5: Coefficient for feature reusage (higher = encourages feature reuse across steps)\n",
        "# lambda_sparse=1e-2: Sparsity regularization (encourages model to use fewer features per step)\n",
        "# optimizer_fn: AdamW optimizer with weight decay for regularization\n",
        "# mask_type='entmax': Attention mechanism type (entmax provides sparse attention)\n",
        "# n_shared=2, n_independent=2: Number of shared/independent layers in feature transformer\n",
        "# momentum=0.95: Batch normalization momentum\n",
        "# clip_value=2.0: Gradient clipping to prevent exploding gradients\n",
        "tabnet_pure = TabNetClassifier(\n",
        "    n_d=64,\n",
        "    n_a=64,\n",
        "    n_steps=5,\n",
        "    gamma=1.5,\n",
        "    lambda_sparse=1e-2,\n",
        "    optimizer_fn=torch.optim.AdamW,\n",
        "    optimizer_params=dict(lr=2e-2, weight_decay=5e-5),\n",
        "    scheduler_fn=None,\n",
        "    scheduler_params=None,\n",
        "    mask_type='entmax',\n",
        "    n_shared=2,\n",
        "    n_independent=2,\n",
        "    momentum=0.95,\n",
        "    clip_value=2.0,\n",
        "    seed=42,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Train TabNet with early stopping\n",
        "# eval_set: Monitor performance on training set\n",
        "# patience=15: Stop if no improvement for 15 epochs (prevents overfitting)\n",
        "# batch_size=1024: Process 1024 samples at once\n",
        "# virtual_batch_size=256: Split batch into smaller virtual batches (helps with batch normalization)\n",
        "# weights: Apply class weights to handle imbalanced data\n",
        "tabnet_pure.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    eval_set=[(X_train, y_train)],\n",
        "    eval_name=['train'],\n",
        "    eval_metric=['auc'],\n",
        "    max_epochs=100,\n",
        "    patience=15,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=256,\n",
        "    num_workers=0,\n",
        "    drop_last=False,\n",
        "    weights=class_weights\n",
        ")\n",
        "\n",
        "print('Pure TabNet training completed')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Threshold Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal threshold: 0.7670\n"
          ]
        }
      ],
      "source": [
        "# Get probability scores from TabNet for threshold optimization\n",
        "tabnet_pure_train_scores = tabnet_pure.predict_proba(X_train)[:, 1]\n",
        "\n",
        "# Find optimal threshold by maximizing F1 score\n",
        "# Tests all possible thresholds and picks the one with best precision-recall balance\n",
        "prec, rec, thresholds = precision_recall_curve(y_train, tabnet_pure_train_scores)\n",
        "f1_scores = 2 * prec * rec / (prec + rec + 1e-9)\n",
        "best_idx = np.nanargmax(f1_scores)\n",
        "tabnet_pure_optimal_threshold = thresholds[max(0, best_idx - 1)] if len(thresholds) > 0 else 0.5\n",
        "\n",
        "print(f'Optimal threshold: {tabnet_pure_optimal_threshold:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Metrics:\n",
            "  ROC-AUC: 0.9270, PR-AUC: 0.8660\n",
            "  F1: 0.7921, Precision: 0.9124, Recall: 0.6998\n",
            "  Specificity: 0.9813\n",
            "\n",
            "Test Metrics:\n",
            "  ROC-AUC: 0.9218, PR-AUC: 0.8608\n",
            "  F1: 0.7946, Precision: 0.9180, Recall: 0.7004\n",
            "  Specificity: 0.9825\n"
          ]
        }
      ],
      "source": [
        "# Convert probabilities to binary predictions using optimal threshold\n",
        "tabnet_pure_train_pred = (tabnet_pure_train_scores >= tabnet_pure_optimal_threshold).astype(int)\n",
        "tabnet_pure_test_scores = tabnet_pure.predict_proba(X_test)[:, 1]\n",
        "tabnet_pure_test_pred = (tabnet_pure_test_scores >= tabnet_pure_optimal_threshold).astype(int)\n",
        "\n",
        "# Calculate performance metrics for training set\n",
        "tabnet_pure_train_metrics = {\n",
        "    'roc_auc': roc_auc_score(y_train, tabnet_pure_train_scores),\n",
        "    'pr_auc': average_precision_score(y_train, tabnet_pure_train_scores),\n",
        "    'f1': f1_score(y_train, tabnet_pure_train_pred),\n",
        "    'precision': precision_score(y_train, tabnet_pure_train_pred),\n",
        "    'recall': recall_score(y_train, tabnet_pure_train_pred)\n",
        "}\n",
        "\n",
        "# Calculate metrics for test set\n",
        "tabnet_pure_test_metrics = {\n",
        "    'roc_auc': roc_auc_score(y_test, tabnet_pure_test_scores),\n",
        "    'pr_auc': average_precision_score(y_test, tabnet_pure_test_scores),\n",
        "    'f1': f1_score(y_test, tabnet_pure_test_pred),\n",
        "    'precision': precision_score(y_test, tabnet_pure_test_pred),\n",
        "    'recall': recall_score(y_test, tabnet_pure_test_pred),\n",
        "    'threshold': tabnet_pure_optimal_threshold\n",
        "}\n",
        "\n",
        "# Calculate specificity from confusion matrix\n",
        "tabnet_pure_train_cm = confusion_matrix(y_train, tabnet_pure_train_pred)\n",
        "tabnet_pure_test_cm = confusion_matrix(y_test, tabnet_pure_test_pred)\n",
        "tabnet_pure_train_specificity = tabnet_pure_train_cm[0, 0] / (tabnet_pure_train_cm[0, 0] + tabnet_pure_train_cm[0, 1] + 1e-9)\n",
        "tabnet_pure_test_specificity = tabnet_pure_test_cm[0, 0] / (tabnet_pure_test_cm[0, 0] + tabnet_pure_test_cm[0, 1] + 1e-9)\n",
        "\n",
        "print('Training Metrics:')\n",
        "print(f\"  ROC-AUC: {tabnet_pure_train_metrics['roc_auc']:.4f}, PR-AUC: {tabnet_pure_train_metrics['pr_auc']:.4f}\")\n",
        "print(f\"  F1: {tabnet_pure_train_metrics['f1']:.4f}, Precision: {tabnet_pure_train_metrics['precision']:.4f}, Recall: {tabnet_pure_train_metrics['recall']:.4f}\")\n",
        "print(f\"  Specificity: {tabnet_pure_train_specificity:.4f}\")\n",
        "\n",
        "print('\\nTest Metrics:')\n",
        "print(f\"  ROC-AUC: {tabnet_pure_test_metrics['roc_auc']:.4f}, PR-AUC: {tabnet_pure_test_metrics['pr_auc']:.4f}\")\n",
        "print(f\"  F1: {tabnet_pure_test_metrics['f1']:.4f}, Precision: {tabnet_pure_test_metrics['precision']:.4f}, Recall: {tabnet_pure_test_metrics['recall']:.4f}\")\n",
        "print(f\"  Specificity: {tabnet_pure_test_specificity:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: tabnet_pure_roc.png\n"
          ]
        }
      ],
      "source": [
        "images_dir = os.path.join(ARTIFACTS_DIR, '03_2_neural_network_images')\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.dpi'] = 150\n",
        "\n",
        "fpr_train, tpr_train, _ = roc_curve(y_train, tabnet_pure_train_scores)\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, tabnet_pure_test_scores)\n",
        "auc_train = auc(fpr_train, tpr_train)\n",
        "auc_test = auc(fpr_test, tpr_test)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.plot(fpr_train, tpr_train, label=f'Train (AUC = {auc_train:.4f})', linewidth=2, linestyle='--')\n",
        "ax.plot(fpr_test, tpr_test, label=f'Test (AUC = {auc_test:.4f})', linewidth=2)\n",
        "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5, label='Random')\n",
        "ax.set_xlabel('False Positive Rate', fontsize=11)\n",
        "ax.set_ylabel('True Positive Rate', fontsize=11)\n",
        "ax.set_title('Pure TabNet - ROC Curve', fontsize=12, fontweight='bold')\n",
        "ax.legend(loc='lower right')\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'tabnet_pure_roc.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: tabnet_pure_roc.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: tabnet_pure_cm.png\n"
          ]
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "sns.heatmap(tabnet_pure_train_cm, annot=True, fmt='d', cmap='Blues', ax=ax1, cbar=False)\n",
        "ax1.set_title('Training Set', fontsize=11, fontweight='bold')\n",
        "ax1.set_xlabel('Predicted')\n",
        "ax1.set_ylabel('Actual')\n",
        "\n",
        "sns.heatmap(tabnet_pure_test_cm, annot=True, fmt='d', cmap='Blues', ax=ax2, cbar=False)\n",
        "ax2.set_title('Test Set', fontsize=11, fontweight='bold')\n",
        "ax2.set_xlabel('Predicted')\n",
        "ax2.set_ylabel('Actual')\n",
        "\n",
        "plt.suptitle('Pure TabNet - Confusion Matrix', fontsize=12, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'tabnet_pure_cm.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: tabnet_pure_cm.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: tabnet_pure_pr.png\n"
          ]
        }
      ],
      "source": [
        "prec_train, rec_train, _ = precision_recall_curve(y_train, tabnet_pure_train_scores)\n",
        "prec_test, rec_test, _ = precision_recall_curve(y_test, tabnet_pure_test_scores)\n",
        "pr_auc_train = average_precision_score(y_train, tabnet_pure_train_scores)\n",
        "pr_auc_test = average_precision_score(y_test, tabnet_pure_test_scores)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.plot(rec_train, prec_train, label=f'Train (AUC = {pr_auc_train:.4f})', linewidth=2, linestyle='--')\n",
        "ax.plot(rec_test, prec_test, label=f'Test (AUC = {pr_auc_test:.4f})', linewidth=2)\n",
        "ax.set_xlabel('Recall', fontsize=11)\n",
        "ax.set_ylabel('Precision', fontsize=11)\n",
        "ax.set_title('Pure TabNet - Precision-Recall Curve', fontsize=12, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'tabnet_pure_pr.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: tabnet_pure_pr.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 2: TabNet + Tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original features: 17, Tokenized features: 32\n"
          ]
        }
      ],
      "source": [
        "# Feature Tokenization: Transform raw features into learned representations\n",
        "# Why tokenize? Raw features might not be in optimal format for TabNet\n",
        "# Tokenizer learns a better feature representation through a small neural network\n",
        "# This can help TabNet work better by providing pre-processed features\n",
        "\n",
        "# Build tokenizer network: 2-layer dense network that compresses features\n",
        "# Input: Original 17 features\n",
        "# Layer 1: 64 units with swish activation (smooth, non-linear transformation)\n",
        "# BatchNormalization: Normalizes activations for stable training\n",
        "# Layer 2: 32 units (compressed representation)\n",
        "# L2 regularization: Prevents overfitting by penalizing large weights\n",
        "tokenizer_input = layers.Input(shape=(input_dim,))\n",
        "tokenized_features = layers.Dense(64, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(tokenizer_input)\n",
        "tokenized_features = layers.BatchNormalization()(tokenized_features)\n",
        "tokenized_features = layers.Dense(32, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(tokenized_features)\n",
        "tokenizer_model = keras.Model(inputs=tokenizer_input, outputs=tokenized_features)\n",
        "\n",
        "# Transform original features into tokenized features\n",
        "# Note: Tokenizer is untrained here - it will learn during TabNet training\n",
        "# This creates a 32-dimensional representation instead of original 17 features\n",
        "X_train_tokenized = tokenizer_model.predict(X_train, verbose=0)\n",
        "X_test_tokenized = tokenizer_model.predict(X_test, verbose=0)\n",
        "\n",
        "print(f'Original features: {X_train.shape[1]}, Tokenized features: {X_train_tokenized.shape[1]}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 57 with best_epoch = 42 and best_train_auc = 0.92098\n",
            "TabNet + Tokenizer training completed\n"
          ]
        }
      ],
      "source": [
        "# TabNet with tokenized features: Same architecture as pure TabNet\n",
        "# But now works on 32 tokenized features instead of 17 original features\n",
        "# This allows TabNet to learn from a potentially better feature representation\n",
        "tabnet_tokenizer = TabNetClassifier(\n",
        "    n_d=64,\n",
        "    n_a=64,\n",
        "    n_steps=5,\n",
        "    gamma=1.5,\n",
        "    lambda_sparse=1e-2,\n",
        "    optimizer_fn=torch.optim.AdamW,\n",
        "    optimizer_params=dict(lr=2e-2, weight_decay=5e-5),\n",
        "    scheduler_fn=None,\n",
        "    scheduler_params=None,\n",
        "    mask_type='entmax',\n",
        "    n_shared=2,\n",
        "    n_independent=2,\n",
        "    momentum=0.95,\n",
        "    clip_value=2.0,\n",
        "    seed=42,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Train on tokenized features instead of raw features\n",
        "tabnet_tokenizer.fit(\n",
        "    X_train_tokenized,\n",
        "    y_train,\n",
        "    eval_set=[(X_train_tokenized, y_train)],\n",
        "    eval_name=['train'],\n",
        "    eval_metric=['auc'],\n",
        "    max_epochs=100,\n",
        "    patience=15,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=256,\n",
        "    num_workers=0,\n",
        "    drop_last=False,\n",
        "    weights=class_weights\n",
        ")\n",
        "\n",
        "print('TabNet + Tokenizer training completed')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Threshold Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal threshold: 0.7065\n"
          ]
        }
      ],
      "source": [
        "# Get predictions and find optimal threshold for TabNet + Tokenizer\n",
        "tabnet_tokenizer_train_scores = tabnet_tokenizer.predict_proba(X_train_tokenized)[:, 1]\n",
        "\n",
        "prec, rec, thresholds = precision_recall_curve(y_train, tabnet_tokenizer_train_scores)\n",
        "f1_scores = 2 * prec * rec / (prec + rec + 1e-9)\n",
        "best_idx = np.nanargmax(f1_scores)\n",
        "tabnet_tokenizer_optimal_threshold = thresholds[max(0, best_idx - 1)] if len(thresholds) > 0 else 0.5\n",
        "\n",
        "print(f'Optimal threshold: {tabnet_tokenizer_optimal_threshold:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Metrics:\n",
            "  ROC-AUC: 0.9210, PR-AUC: 0.8547\n",
            "  F1: 0.7765, Precision: 0.8845, Recall: 0.6921\n",
            "  Specificity: 0.9748\n",
            "\n",
            "Test Metrics:\n",
            "  ROC-AUC: 0.9197, PR-AUC: 0.8462\n",
            "  F1: 0.7747, Precision: 0.8787, Recall: 0.6927\n",
            "  Specificity: 0.9733\n"
          ]
        }
      ],
      "source": [
        "# Evaluate TabNet + Tokenizer model\n",
        "tabnet_tokenizer_train_pred = (tabnet_tokenizer_train_scores >= tabnet_tokenizer_optimal_threshold).astype(int)\n",
        "tabnet_tokenizer_test_scores = tabnet_tokenizer.predict_proba(X_test_tokenized)[:, 1]\n",
        "tabnet_tokenizer_test_pred = (tabnet_tokenizer_test_scores >= tabnet_tokenizer_optimal_threshold).astype(int)\n",
        "\n",
        "tabnet_tokenizer_train_metrics = {\n",
        "    'roc_auc': roc_auc_score(y_train, tabnet_tokenizer_train_scores),\n",
        "    'pr_auc': average_precision_score(y_train, tabnet_tokenizer_train_scores),\n",
        "    'f1': f1_score(y_train, tabnet_tokenizer_train_pred),\n",
        "    'precision': precision_score(y_train, tabnet_tokenizer_train_pred),\n",
        "    'recall': recall_score(y_train, tabnet_tokenizer_train_pred)\n",
        "}\n",
        "\n",
        "tabnet_tokenizer_test_metrics = {\n",
        "    'roc_auc': roc_auc_score(y_test, tabnet_tokenizer_test_scores),\n",
        "    'pr_auc': average_precision_score(y_test, tabnet_tokenizer_test_scores),\n",
        "    'f1': f1_score(y_test, tabnet_tokenizer_test_pred),\n",
        "    'precision': precision_score(y_test, tabnet_tokenizer_test_pred),\n",
        "    'recall': recall_score(y_test, tabnet_tokenizer_test_pred),\n",
        "    'threshold': tabnet_tokenizer_optimal_threshold\n",
        "}\n",
        "\n",
        "tabnet_tokenizer_train_cm = confusion_matrix(y_train, tabnet_tokenizer_train_pred)\n",
        "tabnet_tokenizer_test_cm = confusion_matrix(y_test, tabnet_tokenizer_test_pred)\n",
        "tabnet_tokenizer_train_specificity = tabnet_tokenizer_train_cm[0, 0] / (tabnet_tokenizer_train_cm[0, 0] + tabnet_tokenizer_train_cm[0, 1] + 1e-9)\n",
        "tabnet_tokenizer_test_specificity = tabnet_tokenizer_test_cm[0, 0] / (tabnet_tokenizer_test_cm[0, 0] + tabnet_tokenizer_test_cm[0, 1] + 1e-9)\n",
        "\n",
        "print('Training Metrics:')\n",
        "print(f\"  ROC-AUC: {tabnet_tokenizer_train_metrics['roc_auc']:.4f}, PR-AUC: {tabnet_tokenizer_train_metrics['pr_auc']:.4f}\")\n",
        "print(f\"  F1: {tabnet_tokenizer_train_metrics['f1']:.4f}, Precision: {tabnet_tokenizer_train_metrics['precision']:.4f}, Recall: {tabnet_tokenizer_train_metrics['recall']:.4f}\")\n",
        "print(f\"  Specificity: {tabnet_tokenizer_train_specificity:.4f}\")\n",
        "\n",
        "print('\\nTest Metrics:')\n",
        "print(f\"  ROC-AUC: {tabnet_tokenizer_test_metrics['roc_auc']:.4f}, PR-AUC: {tabnet_tokenizer_test_metrics['pr_auc']:.4f}\")\n",
        "print(f\"  F1: {tabnet_tokenizer_test_metrics['f1']:.4f}, Precision: {tabnet_tokenizer_test_metrics['precision']:.4f}, Recall: {tabnet_tokenizer_test_metrics['recall']:.4f}\")\n",
        "print(f\"  Specificity: {tabnet_tokenizer_test_specificity:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: tabnet_tokenizer_roc.png\n"
          ]
        }
      ],
      "source": [
        "fpr_train, tpr_train, _ = roc_curve(y_train, tabnet_tokenizer_train_scores)\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, tabnet_tokenizer_test_scores)\n",
        "auc_train = auc(fpr_train, tpr_train)\n",
        "auc_test = auc(fpr_test, tpr_test)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.plot(fpr_train, tpr_train, label=f'Train (AUC = {auc_train:.4f})', linewidth=2, linestyle='--')\n",
        "ax.plot(fpr_test, tpr_test, label=f'Test (AUC = {auc_test:.4f})', linewidth=2)\n",
        "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5, label='Random')\n",
        "ax.set_xlabel('False Positive Rate', fontsize=11)\n",
        "ax.set_ylabel('True Positive Rate', fontsize=11)\n",
        "ax.set_title('TabNet + Tokenizer - ROC Curve', fontsize=12, fontweight='bold')\n",
        "ax.legend(loc='lower right')\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'tabnet_tokenizer_roc.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: tabnet_tokenizer_roc.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: tabnet_tokenizer_cm.png\n"
          ]
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "sns.heatmap(tabnet_tokenizer_train_cm, annot=True, fmt='d', cmap='Blues', ax=ax1, cbar=False)\n",
        "ax1.set_title('Training Set', fontsize=11, fontweight='bold')\n",
        "ax1.set_xlabel('Predicted')\n",
        "ax1.set_ylabel('Actual')\n",
        "\n",
        "sns.heatmap(tabnet_tokenizer_test_cm, annot=True, fmt='d', cmap='Blues', ax=ax2, cbar=False)\n",
        "ax2.set_title('Test Set', fontsize=11, fontweight='bold')\n",
        "ax2.set_xlabel('Predicted')\n",
        "ax2.set_ylabel('Actual')\n",
        "\n",
        "plt.suptitle('TabNet + Tokenizer - Confusion Matrix', fontsize=12, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'tabnet_tokenizer_cm.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: tabnet_tokenizer_cm.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: tabnet_tokenizer_pr.png\n"
          ]
        }
      ],
      "source": [
        "prec_train, rec_train, _ = precision_recall_curve(y_train, tabnet_tokenizer_train_scores)\n",
        "prec_test, rec_test, _ = precision_recall_curve(y_test, tabnet_tokenizer_test_scores)\n",
        "pr_auc_train = average_precision_score(y_train, tabnet_tokenizer_train_scores)\n",
        "pr_auc_test = average_precision_score(y_test, tabnet_tokenizer_test_scores)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.plot(rec_train, prec_train, label=f'Train (AUC = {pr_auc_train:.4f})', linewidth=2, linestyle='--')\n",
        "ax.plot(rec_test, prec_test, label=f'Test (AUC = {pr_auc_test:.4f})', linewidth=2)\n",
        "ax.set_xlabel('Recall', fontsize=11)\n",
        "ax.set_ylabel('Precision', fontsize=11)\n",
        "ax.set_title('TabNet + Tokenizer - Precision-Recall Curve', fontsize=12, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'tabnet_tokenizer_pr.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: tabnet_tokenizer_pr.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 3: Deep & Cross Network (DCN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deep & Cross Network (DCN): Combines explicit feature interactions with deep learning\n",
        "# Architecture has two paths: Cross Network (feature interactions) + Deep Network (non-linear patterns)\n",
        "\n",
        "dcn_input = layers.Input(shape=(input_dim,))\n",
        "\n",
        "# CROSS NETWORK: Explicitly models feature interactions\n",
        "# Formula: x_{l+1} = x_0 * (W_l * x_l + b_l) + x_l\n",
        "# This creates polynomial feature interactions (e.g., age * income, credit_score^2)\n",
        "# Each cross layer learns higher-order interactions between features\n",
        "x0 = dcn_input\n",
        "x_l = x0\n",
        "\n",
        "for i in range(3):\n",
        "    # Linear transformation\n",
        "    x_l = layers.Dense(input_dim, use_bias=False, kernel_regularizer=regularizers.l2(1e-4))(x_l)\n",
        "    # Element-wise multiplication with original input (creates interactions)\n",
        "    x_l = layers.Multiply()([x0, x_l])\n",
        "    # Residual connection (adds original input back)\n",
        "    x_l = layers.Add()([x_l, x0])\n",
        "\n",
        "cross_output = x_l\n",
        "\n",
        "# DEEP NETWORK: Standard feedforward network for non-linear patterns\n",
        "# Processes features through multiple dense layers with non-linear activations\n",
        "deep = layers.Dense(256, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(dcn_input)\n",
        "deep = layers.BatchNormalization()(deep)\n",
        "deep = layers.Dropout(0.3)(deep)\n",
        "\n",
        "deep = layers.Dense(128, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(deep)\n",
        "deep = layers.BatchNormalization()(deep)\n",
        "deep = layers.Dropout(0.2)(deep)\n",
        "\n",
        "deep = layers.Dense(64, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(deep)\n",
        "deep = layers.BatchNormalization()(deep)\n",
        "deep = layers.Dropout(0.15)(deep)\n",
        "\n",
        "# COMBINE: Concatenate cross network output (feature interactions) with deep network output (non-linear patterns)\n",
        "# This allows model to use both explicit interactions and learned patterns\n",
        "combined = layers.Concatenate()([cross_output, deep])\n",
        "combined = layers.Dense(128, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(combined)\n",
        "combined = layers.BatchNormalization()(combined)\n",
        "combined = layers.Dropout(0.2)(combined)\n",
        "combined = layers.Dense(64, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(combined)\n",
        "combined = layers.BatchNormalization()(combined)\n",
        "\n",
        "# Final output: Binary classification probability\n",
        "dcn_output = layers.Dense(1, activation='sigmoid')(combined)\n",
        "\n",
        "dcn_model = keras.Model(inputs=dcn_input, outputs=dcn_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.1535 - pr_auc: 0.5476 - roc_auc: 0.7479 - val_loss: 0.1084 - val_pr_auc: 0.5718 - val_roc_auc: 0.7790 - learning_rate: 0.0010\n",
            "Epoch 2/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1007 - pr_auc: 0.6733 - roc_auc: 0.8038 - val_loss: 0.0976 - val_pr_auc: 0.6189 - val_roc_auc: 0.8116 - learning_rate: 0.0010\n",
            "Epoch 3/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0889 - pr_auc: 0.7101 - roc_auc: 0.8352 - val_loss: 0.0957 - val_pr_auc: 0.6157 - val_roc_auc: 0.8173 - learning_rate: 0.0010\n",
            "Epoch 4/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0832 - pr_auc: 0.7370 - roc_auc: 0.8562 - val_loss: 0.0943 - val_pr_auc: 0.6447 - val_roc_auc: 0.8425 - learning_rate: 0.0010\n",
            "Epoch 5/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0801 - pr_auc: 0.7521 - roc_auc: 0.8672 - val_loss: 0.0925 - val_pr_auc: 0.6635 - val_roc_auc: 0.8506 - learning_rate: 0.0010\n",
            "Epoch 6/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0767 - pr_auc: 0.7702 - roc_auc: 0.8766 - val_loss: 0.0906 - val_pr_auc: 0.6835 - val_roc_auc: 0.8544 - learning_rate: 0.0010\n",
            "Epoch 7/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0742 - pr_auc: 0.7767 - roc_auc: 0.8803 - val_loss: 0.0873 - val_pr_auc: 0.7140 - val_roc_auc: 0.8639 - learning_rate: 0.0010\n",
            "Epoch 8/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0714 - pr_auc: 0.7880 - roc_auc: 0.8868 - val_loss: 0.0825 - val_pr_auc: 0.7305 - val_roc_auc: 0.8722 - learning_rate: 0.0010\n",
            "Epoch 9/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0690 - pr_auc: 0.7983 - roc_auc: 0.8935 - val_loss: 0.0782 - val_pr_auc: 0.7679 - val_roc_auc: 0.8852 - learning_rate: 0.0010\n",
            "Epoch 10/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0666 - pr_auc: 0.8052 - roc_auc: 0.8942 - val_loss: 0.0754 - val_pr_auc: 0.7849 - val_roc_auc: 0.8913 - learning_rate: 0.0010\n",
            "Epoch 11/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0645 - pr_auc: 0.8085 - roc_auc: 0.8969 - val_loss: 0.0721 - val_pr_auc: 0.7839 - val_roc_auc: 0.8916 - learning_rate: 0.0010\n",
            "Epoch 12/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0626 - pr_auc: 0.8121 - roc_auc: 0.8988 - val_loss: 0.0694 - val_pr_auc: 0.8023 - val_roc_auc: 0.8961 - learning_rate: 0.0010\n",
            "Epoch 13/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0605 - pr_auc: 0.8157 - roc_auc: 0.9004 - val_loss: 0.0672 - val_pr_auc: 0.7991 - val_roc_auc: 0.8967 - learning_rate: 0.0010\n",
            "Epoch 14/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0582 - pr_auc: 0.8242 - roc_auc: 0.9058 - val_loss: 0.0647 - val_pr_auc: 0.8044 - val_roc_auc: 0.8974 - learning_rate: 0.0010\n",
            "Epoch 15/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0565 - pr_auc: 0.8257 - roc_auc: 0.9062 - val_loss: 0.0624 - val_pr_auc: 0.8156 - val_roc_auc: 0.9013 - learning_rate: 0.0010\n",
            "Epoch 16/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0547 - pr_auc: 0.8291 - roc_auc: 0.9066 - val_loss: 0.0611 - val_pr_auc: 0.8211 - val_roc_auc: 0.9031 - learning_rate: 0.0010\n",
            "Epoch 17/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0533 - pr_auc: 0.8285 - roc_auc: 0.9054 - val_loss: 0.0591 - val_pr_auc: 0.8217 - val_roc_auc: 0.9045 - learning_rate: 0.0010\n",
            "Epoch 18/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0519 - pr_auc: 0.8287 - roc_auc: 0.9070 - val_loss: 0.0564 - val_pr_auc: 0.8240 - val_roc_auc: 0.9052 - learning_rate: 0.0010\n",
            "Epoch 19/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0497 - pr_auc: 0.8371 - roc_auc: 0.9089 - val_loss: 0.0551 - val_pr_auc: 0.8280 - val_roc_auc: 0.9079 - learning_rate: 0.0010\n",
            "Epoch 20/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0488 - pr_auc: 0.8360 - roc_auc: 0.9106 - val_loss: 0.0543 - val_pr_auc: 0.8224 - val_roc_auc: 0.9043 - learning_rate: 0.0010\n",
            "Epoch 21/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0470 - pr_auc: 0.8407 - roc_auc: 0.9112 - val_loss: 0.0525 - val_pr_auc: 0.8296 - val_roc_auc: 0.9069 - learning_rate: 0.0010\n",
            "Epoch 22/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0461 - pr_auc: 0.8396 - roc_auc: 0.9116 - val_loss: 0.0519 - val_pr_auc: 0.8267 - val_roc_auc: 0.9053 - learning_rate: 0.0010\n",
            "Epoch 23/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0447 - pr_auc: 0.8422 - roc_auc: 0.9110 - val_loss: 0.0510 - val_pr_auc: 0.8291 - val_roc_auc: 0.9061 - learning_rate: 0.0010\n",
            "Epoch 24/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0436 - pr_auc: 0.8435 - roc_auc: 0.9124 - val_loss: 0.0502 - val_pr_auc: 0.8262 - val_roc_auc: 0.9037 - learning_rate: 0.0010\n",
            "Epoch 25/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0422 - pr_auc: 0.8499 - roc_auc: 0.9154 - val_loss: 0.0486 - val_pr_auc: 0.8283 - val_roc_auc: 0.9051 - learning_rate: 5.0000e-04\n",
            "Epoch 26/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0418 - pr_auc: 0.8486 - roc_auc: 0.9160 - val_loss: 0.0480 - val_pr_auc: 0.8333 - val_roc_auc: 0.9061 - learning_rate: 5.0000e-04\n",
            "Epoch 27/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0409 - pr_auc: 0.8530 - roc_auc: 0.9177 - val_loss: 0.0472 - val_pr_auc: 0.8368 - val_roc_auc: 0.9083 - learning_rate: 5.0000e-04\n",
            "Epoch 28/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0405 - pr_auc: 0.8517 - roc_auc: 0.9170 - val_loss: 0.0469 - val_pr_auc: 0.8364 - val_roc_auc: 0.9081 - learning_rate: 5.0000e-04\n",
            "Epoch 29/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0399 - pr_auc: 0.8526 - roc_auc: 0.9177 - val_loss: 0.0463 - val_pr_auc: 0.8352 - val_roc_auc: 0.9081 - learning_rate: 5.0000e-04\n",
            "Epoch 30/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0398 - pr_auc: 0.8505 - roc_auc: 0.9156 - val_loss: 0.0450 - val_pr_auc: 0.8383 - val_roc_auc: 0.9102 - learning_rate: 5.0000e-04\n",
            "Epoch 31/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0388 - pr_auc: 0.8533 - roc_auc: 0.9175 - val_loss: 0.0439 - val_pr_auc: 0.8404 - val_roc_auc: 0.9119 - learning_rate: 5.0000e-04\n",
            "Epoch 32/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0387 - pr_auc: 0.8515 - roc_auc: 0.9174 - val_loss: 0.0438 - val_pr_auc: 0.8382 - val_roc_auc: 0.9103 - learning_rate: 5.0000e-04\n",
            "Epoch 33/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0381 - pr_auc: 0.8530 - roc_auc: 0.9180 - val_loss: 0.0431 - val_pr_auc: 0.8404 - val_roc_auc: 0.9101 - learning_rate: 5.0000e-04\n",
            "Epoch 34/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0377 - pr_auc: 0.8540 - roc_auc: 0.9181 - val_loss: 0.0421 - val_pr_auc: 0.8418 - val_roc_auc: 0.9116 - learning_rate: 5.0000e-04\n",
            "Epoch 35/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0373 - pr_auc: 0.8538 - roc_auc: 0.9187 - val_loss: 0.0420 - val_pr_auc: 0.8396 - val_roc_auc: 0.9099 - learning_rate: 5.0000e-04\n",
            "Epoch 36/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0369 - pr_auc: 0.8539 - roc_auc: 0.9183 - val_loss: 0.0419 - val_pr_auc: 0.8406 - val_roc_auc: 0.9101 - learning_rate: 5.0000e-04\n",
            "Epoch 37/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0362 - pr_auc: 0.8577 - roc_auc: 0.9204 - val_loss: 0.0415 - val_pr_auc: 0.8437 - val_roc_auc: 0.9105 - learning_rate: 2.5000e-04\n",
            "Epoch 38/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0358 - pr_auc: 0.8599 - roc_auc: 0.9215 - val_loss: 0.0410 - val_pr_auc: 0.8476 - val_roc_auc: 0.9119 - learning_rate: 2.5000e-04\n",
            "Epoch 39/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0356 - pr_auc: 0.8594 - roc_auc: 0.9216 - val_loss: 0.0409 - val_pr_auc: 0.8460 - val_roc_auc: 0.9117 - learning_rate: 2.5000e-04\n",
            "Epoch 40/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0356 - pr_auc: 0.8583 - roc_auc: 0.9212 - val_loss: 0.0405 - val_pr_auc: 0.8453 - val_roc_auc: 0.9122 - learning_rate: 2.5000e-04\n",
            "Epoch 41/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0355 - pr_auc: 0.8567 - roc_auc: 0.9187 - val_loss: 0.0400 - val_pr_auc: 0.8476 - val_roc_auc: 0.9137 - learning_rate: 2.5000e-04\n",
            "Epoch 42/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0350 - pr_auc: 0.8587 - roc_auc: 0.9205 - val_loss: 0.0395 - val_pr_auc: 0.8480 - val_roc_auc: 0.9131 - learning_rate: 2.5000e-04\n",
            "Epoch 43/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0349 - pr_auc: 0.8604 - roc_auc: 0.9216 - val_loss: 0.0394 - val_pr_auc: 0.8487 - val_roc_auc: 0.9134 - learning_rate: 2.5000e-04\n",
            "Epoch 44/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0348 - pr_auc: 0.8582 - roc_auc: 0.9203 - val_loss: 0.0391 - val_pr_auc: 0.8475 - val_roc_auc: 0.9134 - learning_rate: 2.5000e-04\n",
            "Epoch 45/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0344 - pr_auc: 0.8595 - roc_auc: 0.9205 - val_loss: 0.0392 - val_pr_auc: 0.8449 - val_roc_auc: 0.9118 - learning_rate: 2.5000e-04\n",
            "Epoch 46/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0342 - pr_auc: 0.8618 - roc_auc: 0.9224 - val_loss: 0.0391 - val_pr_auc: 0.8450 - val_roc_auc: 0.9109 - learning_rate: 2.5000e-04\n",
            "Epoch 47/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0339 - pr_auc: 0.8627 - roc_auc: 0.9232 - val_loss: 0.0391 - val_pr_auc: 0.8485 - val_roc_auc: 0.9122 - learning_rate: 1.2500e-04\n",
            "Epoch 48/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0338 - pr_auc: 0.8618 - roc_auc: 0.9226 - val_loss: 0.0387 - val_pr_auc: 0.8486 - val_roc_auc: 0.9121 - learning_rate: 1.2500e-04\n",
            "Epoch 49/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0338 - pr_auc: 0.8617 - roc_auc: 0.9220 - val_loss: 0.0384 - val_pr_auc: 0.8485 - val_roc_auc: 0.9122 - learning_rate: 1.2500e-04\n",
            "Epoch 50/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0336 - pr_auc: 0.8628 - roc_auc: 0.9237 - val_loss: 0.0384 - val_pr_auc: 0.8493 - val_roc_auc: 0.9126 - learning_rate: 1.2500e-04\n",
            "Epoch 51/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0336 - pr_auc: 0.8619 - roc_auc: 0.9234 - val_loss: 0.0382 - val_pr_auc: 0.8506 - val_roc_auc: 0.9137 - learning_rate: 1.2500e-04\n",
            "Epoch 52/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0334 - pr_auc: 0.8631 - roc_auc: 0.9235 - val_loss: 0.0381 - val_pr_auc: 0.8515 - val_roc_auc: 0.9136 - learning_rate: 6.2500e-05\n",
            "Epoch 53/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0332 - pr_auc: 0.8636 - roc_auc: 0.9236 - val_loss: 0.0378 - val_pr_auc: 0.8519 - val_roc_auc: 0.9142 - learning_rate: 6.2500e-05\n",
            "Epoch 54/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0333 - pr_auc: 0.8645 - roc_auc: 0.9242 - val_loss: 0.0378 - val_pr_auc: 0.8527 - val_roc_auc: 0.9148 - learning_rate: 6.2500e-05\n",
            "Epoch 55/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0333 - pr_auc: 0.8628 - roc_auc: 0.9240 - val_loss: 0.0377 - val_pr_auc: 0.8523 - val_roc_auc: 0.9138 - learning_rate: 6.2500e-05\n",
            "Epoch 56/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0329 - pr_auc: 0.8656 - roc_auc: 0.9248 - val_loss: 0.0376 - val_pr_auc: 0.8522 - val_roc_auc: 0.9140 - learning_rate: 6.2500e-05\n",
            "Epoch 57/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0330 - pr_auc: 0.8646 - roc_auc: 0.9250 - val_loss: 0.0376 - val_pr_auc: 0.8521 - val_roc_auc: 0.9133 - learning_rate: 6.2500e-05\n",
            "Epoch 58/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0332 - pr_auc: 0.8633 - roc_auc: 0.9239 - val_loss: 0.0376 - val_pr_auc: 0.8517 - val_roc_auc: 0.9141 - learning_rate: 6.2500e-05\n",
            "Epoch 59/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0330 - pr_auc: 0.8637 - roc_auc: 0.9242 - val_loss: 0.0375 - val_pr_auc: 0.8518 - val_roc_auc: 0.9136 - learning_rate: 6.2500e-05\n",
            "Epoch 60/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0330 - pr_auc: 0.8633 - roc_auc: 0.9235 - val_loss: 0.0373 - val_pr_auc: 0.8527 - val_roc_auc: 0.9142 - learning_rate: 3.1250e-05\n",
            "Epoch 61/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0327 - pr_auc: 0.8667 - roc_auc: 0.9265 - val_loss: 0.0373 - val_pr_auc: 0.8526 - val_roc_auc: 0.9139 - learning_rate: 3.1250e-05\n",
            "Epoch 62/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0327 - pr_auc: 0.8653 - roc_auc: 0.9243 - val_loss: 0.0371 - val_pr_auc: 0.8529 - val_roc_auc: 0.9141 - learning_rate: 3.1250e-05\n",
            "Epoch 63/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0328 - pr_auc: 0.8659 - roc_auc: 0.9264 - val_loss: 0.0372 - val_pr_auc: 0.8527 - val_roc_auc: 0.9138 - learning_rate: 3.1250e-05\n",
            "Epoch 64/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0326 - pr_auc: 0.8664 - roc_auc: 0.9255 - val_loss: 0.0370 - val_pr_auc: 0.8527 - val_roc_auc: 0.9141 - learning_rate: 3.1250e-05\n",
            "Epoch 65/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0327 - pr_auc: 0.8669 - roc_auc: 0.9262 - val_loss: 0.0371 - val_pr_auc: 0.8528 - val_roc_auc: 0.9140 - learning_rate: 1.5625e-05\n",
            "Epoch 66/80\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0326 - pr_auc: 0.8657 - roc_auc: 0.9255 - val_loss: 0.0370 - val_pr_auc: 0.8525 - val_roc_auc: 0.9138 - learning_rate: 1.5625e-05\n",
            "DCN trained in 66 epochs\n"
          ]
        }
      ],
      "source": [
        "# Compile DCN model with focal loss for imbalanced data\n",
        "# Focal loss focuses on hard examples and handles class imbalance better than standard cross-entropy\n",
        "dcn_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=focal_loss,\n",
        "    metrics=[keras.metrics.AUC(name='roc_auc', curve='ROC'), keras.metrics.AUC(name='pr_auc', curve='PR')]\n",
        ")\n",
        "\n",
        "# Early stopping: Stop training if validation ROC-AUC doesn't improve for 12 epochs\n",
        "# restore_best_weights: Keep the best model weights (not the last epoch)\n",
        "dcn_early_stop = keras.callbacks.EarlyStopping(monitor='val_roc_auc', mode='max', patience=12, restore_best_weights=True)\n",
        "\n",
        "# Learning rate reduction: If validation performance plateaus, reduce learning rate by half\n",
        "# This helps fine-tune the model when it gets stuck\n",
        "dcn_lr_reduce = keras.callbacks.ReduceLROnPlateau(monitor='val_roc_auc', mode='max', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "# Train model with 10% validation split for monitoring\n",
        "dcn_history = dcn_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=80,\n",
        "    batch_size=512,\n",
        "    callbacks=[dcn_early_stop, dcn_lr_reduce],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f'DCN trained in {len(dcn_history.history[\"roc_auc\"])} epochs')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Threshold Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal threshold: 0.3076\n"
          ]
        }
      ],
      "source": [
        "# Get predictions and optimize threshold for DCN\n",
        "dcn_train_scores = dcn_model.predict(X_train, verbose=0).ravel()\n",
        "\n",
        "prec, rec, thresholds = precision_recall_curve(y_train, dcn_train_scores)\n",
        "f1_scores = 2 * prec * rec / (prec + rec + 1e-9)\n",
        "best_idx = np.nanargmax(f1_scores)\n",
        "dcn_optimal_threshold = thresholds[max(0, best_idx - 1)] if len(thresholds) > 0 else 0.5\n",
        "\n",
        "print(f'Optimal threshold: {dcn_optimal_threshold:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Metrics:\n",
            "  ROC-AUC: 0.9225, PR-AUC: 0.8616\n",
            "  F1: 0.7925, Precision: 0.9076, Recall: 0.7033\n",
            "  Specificity: 0.9800\n",
            "\n",
            "Test Metrics:\n",
            "  ROC-AUC: 0.9251, PR-AUC: 0.8653\n",
            "  F1: 0.7933, Precision: 0.9076, Recall: 0.7046\n",
            "  Specificity: 0.9800\n"
          ]
        }
      ],
      "source": [
        "# Evaluate DCN model performance\n",
        "dcn_train_pred = (dcn_train_scores >= dcn_optimal_threshold).astype(int)\n",
        "dcn_test_scores = dcn_model.predict(X_test, verbose=0).ravel()\n",
        "dcn_test_pred = (dcn_test_scores >= dcn_optimal_threshold).astype(int)\n",
        "\n",
        "dcn_train_metrics = {\n",
        "    'roc_auc': roc_auc_score(y_train, dcn_train_scores),\n",
        "    'pr_auc': average_precision_score(y_train, dcn_train_scores),\n",
        "    'f1': f1_score(y_train, dcn_train_pred),\n",
        "    'precision': precision_score(y_train, dcn_train_pred),\n",
        "    'recall': recall_score(y_train, dcn_train_pred)\n",
        "}\n",
        "\n",
        "dcn_test_metrics = {\n",
        "    'roc_auc': roc_auc_score(y_test, dcn_test_scores),\n",
        "    'pr_auc': average_precision_score(y_test, dcn_test_scores),\n",
        "    'f1': f1_score(y_test, dcn_test_pred),\n",
        "    'precision': precision_score(y_test, dcn_test_pred),\n",
        "    'recall': recall_score(y_test, dcn_test_pred),\n",
        "    'threshold': dcn_optimal_threshold\n",
        "}\n",
        "\n",
        "dcn_train_cm = confusion_matrix(y_train, dcn_train_pred)\n",
        "dcn_test_cm = confusion_matrix(y_test, dcn_test_pred)\n",
        "dcn_train_specificity = dcn_train_cm[0, 0] / (dcn_train_cm[0, 0] + dcn_train_cm[0, 1] + 1e-9)\n",
        "dcn_test_specificity = dcn_test_cm[0, 0] / (dcn_test_cm[0, 0] + dcn_test_cm[0, 1] + 1e-9)\n",
        "\n",
        "print('Training Metrics:')\n",
        "print(f\"  ROC-AUC: {dcn_train_metrics['roc_auc']:.4f}, PR-AUC: {dcn_train_metrics['pr_auc']:.4f}\")\n",
        "print(f\"  F1: {dcn_train_metrics['f1']:.4f}, Precision: {dcn_train_metrics['precision']:.4f}, Recall: {dcn_train_metrics['recall']:.4f}\")\n",
        "print(f\"  Specificity: {dcn_train_specificity:.4f}\")\n",
        "\n",
        "print('\\nTest Metrics:')\n",
        "print(f\"  ROC-AUC: {dcn_test_metrics['roc_auc']:.4f}, PR-AUC: {dcn_test_metrics['pr_auc']:.4f}\")\n",
        "print(f\"  F1: {dcn_test_metrics['f1']:.4f}, Precision: {dcn_test_metrics['precision']:.4f}, Recall: {dcn_test_metrics['recall']:.4f}\")\n",
        "print(f\"  Specificity: {dcn_test_specificity:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: dcn_roc.png\n"
          ]
        }
      ],
      "source": [
        "fpr_train, tpr_train, _ = roc_curve(y_train, dcn_train_scores)\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, dcn_test_scores)\n",
        "auc_train = auc(fpr_train, tpr_train)\n",
        "auc_test = auc(fpr_test, tpr_test)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.plot(fpr_train, tpr_train, label=f'Train (AUC = {auc_train:.4f})', linewidth=2, linestyle='--')\n",
        "ax.plot(fpr_test, tpr_test, label=f'Test (AUC = {auc_test:.4f})', linewidth=2)\n",
        "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5, label='Random')\n",
        "ax.set_xlabel('False Positive Rate', fontsize=11)\n",
        "ax.set_ylabel('True Positive Rate', fontsize=11)\n",
        "ax.set_title('Deep & Cross Network - ROC Curve', fontsize=12, fontweight='bold')\n",
        "ax.legend(loc='lower right')\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'dcn_roc.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: dcn_roc.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: dcn_cm.png\n"
          ]
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "sns.heatmap(dcn_train_cm, annot=True, fmt='d', cmap='Blues', ax=ax1, cbar=False)\n",
        "ax1.set_title('Training Set', fontsize=11, fontweight='bold')\n",
        "ax1.set_xlabel('Predicted')\n",
        "ax1.set_ylabel('Actual')\n",
        "\n",
        "sns.heatmap(dcn_test_cm, annot=True, fmt='d', cmap='Blues', ax=ax2, cbar=False)\n",
        "ax2.set_title('Test Set', fontsize=11, fontweight='bold')\n",
        "ax2.set_xlabel('Predicted')\n",
        "ax2.set_ylabel('Actual')\n",
        "\n",
        "plt.suptitle('Deep & Cross Network - Confusion Matrix', fontsize=12, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'dcn_cm.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: dcn_cm.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: dcn_pr.png\n"
          ]
        }
      ],
      "source": [
        "prec_train, rec_train, _ = precision_recall_curve(y_train, dcn_train_scores)\n",
        "prec_test, rec_test, _ = precision_recall_curve(y_test, dcn_test_scores)\n",
        "pr_auc_train = average_precision_score(y_train, dcn_train_scores)\n",
        "pr_auc_test = average_precision_score(y_test, dcn_test_scores)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.plot(rec_train, prec_train, label=f'Train (AUC = {pr_auc_train:.4f})', linewidth=2, linestyle='--')\n",
        "ax.plot(rec_test, prec_test, label=f'Test (AUC = {pr_auc_test:.4f})', linewidth=2)\n",
        "ax.set_xlabel('Recall', fontsize=11)\n",
        "ax.set_ylabel('Precision', fontsize=11)\n",
        "ax.set_title('Deep & Cross Network - Precision-Recall Curve', fontsize=12, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'dcn_pr.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: dcn_pr.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 4: Residual Neural Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Residual Neural Network: Deep network with skip connections\n",
        "# Residual connections allow gradients to flow directly through the network\n",
        "# This helps train very deep networks by preventing vanishing gradient problem\n",
        "\n",
        "residual_input = layers.Input(shape=(input_dim,))\n",
        "\n",
        "# First block: Expand to 512 dimensions\n",
        "x = layers.Dense(512, kernel_regularizer=regularizers.l2(1e-4))(residual_input)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('swish')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "# Save this for residual connection (skip connection)\n",
        "residual_1 = x\n",
        "\n",
        "# Second block: Compress to 256 dimensions\n",
        "x = layers.Dense(256, kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('swish')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "# Third block: Expand back to 512 and add residual connection\n",
        "# The Add layer combines current output with saved residual_1\n",
        "# This allows the network to learn identity mappings if needed (makes training easier)\n",
        "x = layers.Dense(512, kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Add()([x, residual_1])  # Residual connection: adds original 512-dim output\n",
        "x = layers.Activation('swish')(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "\n",
        "# Continue with standard feedforward layers\n",
        "x = layers.Dense(128, kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('swish')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "\n",
        "x = layers.Dense(64, kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('swish')(x)\n",
        "x = layers.Dropout(0.15)(x)\n",
        "\n",
        "# Final output: Binary classification probability\n",
        "residual_output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "residual_model = keras.Model(inputs=residual_input, outputs=residual_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.1686 - pr_auc: 0.5709 - roc_auc: 0.7745 - val_loss: 0.1537 - val_pr_auc: 0.6789 - val_roc_auc: 0.8548 - learning_rate: 0.0010\n",
            "Epoch 2/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.1343 - pr_auc: 0.7011 - roc_auc: 0.8444 - val_loss: 0.1353 - val_pr_auc: 0.6575 - val_roc_auc: 0.8500 - learning_rate: 0.0010\n",
            "Epoch 3/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.1229 - pr_auc: 0.7427 - roc_auc: 0.8661 - val_loss: 0.1299 - val_pr_auc: 0.6470 - val_roc_auc: 0.8443 - learning_rate: 0.0010\n",
            "Epoch 4/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.1140 - pr_auc: 0.7611 - roc_auc: 0.8757 - val_loss: 0.1232 - val_pr_auc: 0.6628 - val_roc_auc: 0.8539 - learning_rate: 0.0010\n",
            "Epoch 5/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.1053 - pr_auc: 0.7815 - roc_auc: 0.8832 - val_loss: 0.1162 - val_pr_auc: 0.6834 - val_roc_auc: 0.8597 - learning_rate: 0.0010\n",
            "Epoch 6/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0973 - pr_auc: 0.7887 - roc_auc: 0.8858 - val_loss: 0.1072 - val_pr_auc: 0.7047 - val_roc_auc: 0.8697 - learning_rate: 0.0010\n",
            "Epoch 7/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0900 - pr_auc: 0.7994 - roc_auc: 0.8928 - val_loss: 0.0974 - val_pr_auc: 0.7182 - val_roc_auc: 0.8734 - learning_rate: 0.0010\n",
            "Epoch 8/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0838 - pr_auc: 0.7999 - roc_auc: 0.8924 - val_loss: 0.0892 - val_pr_auc: 0.7513 - val_roc_auc: 0.8854 - learning_rate: 0.0010\n",
            "Epoch 9/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0776 - pr_auc: 0.8085 - roc_auc: 0.8932 - val_loss: 0.0805 - val_pr_auc: 0.7776 - val_roc_auc: 0.8934 - learning_rate: 0.0010\n",
            "Epoch 10/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0725 - pr_auc: 0.8070 - roc_auc: 0.8941 - val_loss: 0.0736 - val_pr_auc: 0.7889 - val_roc_auc: 0.8988 - learning_rate: 0.0010\n",
            "Epoch 11/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0672 - pr_auc: 0.8179 - roc_auc: 0.8987 - val_loss: 0.0679 - val_pr_auc: 0.8081 - val_roc_auc: 0.9043 - learning_rate: 0.0010\n",
            "Epoch 12/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0625 - pr_auc: 0.8219 - roc_auc: 0.9015 - val_loss: 0.0639 - val_pr_auc: 0.8184 - val_roc_auc: 0.9048 - learning_rate: 0.0010\n",
            "Epoch 13/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0586 - pr_auc: 0.8255 - roc_auc: 0.9022 - val_loss: 0.0602 - val_pr_auc: 0.8293 - val_roc_auc: 0.9096 - learning_rate: 0.0010\n",
            "Epoch 14/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0552 - pr_auc: 0.8280 - roc_auc: 0.9036 - val_loss: 0.0568 - val_pr_auc: 0.8358 - val_roc_auc: 0.9119 - learning_rate: 0.0010\n",
            "Epoch 15/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0522 - pr_auc: 0.8296 - roc_auc: 0.9047 - val_loss: 0.0535 - val_pr_auc: 0.8398 - val_roc_auc: 0.9126 - learning_rate: 0.0010\n",
            "Epoch 16/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0495 - pr_auc: 0.8327 - roc_auc: 0.9049 - val_loss: 0.0496 - val_pr_auc: 0.8387 - val_roc_auc: 0.9125 - learning_rate: 0.0010\n",
            "Epoch 17/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0476 - pr_auc: 0.8304 - roc_auc: 0.9040 - val_loss: 0.0467 - val_pr_auc: 0.8428 - val_roc_auc: 0.9118 - learning_rate: 0.0010\n",
            "Epoch 18/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0456 - pr_auc: 0.8314 - roc_auc: 0.9053 - val_loss: 0.0455 - val_pr_auc: 0.8407 - val_roc_auc: 0.9139 - learning_rate: 0.0010\n",
            "Epoch 19/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0434 - pr_auc: 0.8355 - roc_auc: 0.9074 - val_loss: 0.0432 - val_pr_auc: 0.8491 - val_roc_auc: 0.9149 - learning_rate: 0.0010\n",
            "Epoch 20/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0417 - pr_auc: 0.8385 - roc_auc: 0.9066 - val_loss: 0.0420 - val_pr_auc: 0.8493 - val_roc_auc: 0.9157 - learning_rate: 0.0010\n",
            "Epoch 21/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0406 - pr_auc: 0.8360 - roc_auc: 0.9089 - val_loss: 0.0411 - val_pr_auc: 0.8443 - val_roc_auc: 0.9120 - learning_rate: 0.0010\n",
            "Epoch 22/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0388 - pr_auc: 0.8405 - roc_auc: 0.9085 - val_loss: 0.0402 - val_pr_auc: 0.8442 - val_roc_auc: 0.9126 - learning_rate: 0.0010\n",
            "Epoch 23/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0382 - pr_auc: 0.8382 - roc_auc: 0.9079 - val_loss: 0.0394 - val_pr_auc: 0.8460 - val_roc_auc: 0.9127 - learning_rate: 0.0010\n",
            "Epoch 24/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0365 - pr_auc: 0.8442 - roc_auc: 0.9120 - val_loss: 0.0371 - val_pr_auc: 0.8548 - val_roc_auc: 0.9170 - learning_rate: 0.0010\n",
            "Epoch 25/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0361 - pr_auc: 0.8413 - roc_auc: 0.9095 - val_loss: 0.0355 - val_pr_auc: 0.8534 - val_roc_auc: 0.9159 - learning_rate: 0.0010\n",
            "Epoch 26/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0354 - pr_auc: 0.8422 - roc_auc: 0.9107 - val_loss: 0.0362 - val_pr_auc: 0.8534 - val_roc_auc: 0.9182 - learning_rate: 0.0010\n",
            "Epoch 27/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0346 - pr_auc: 0.8405 - roc_auc: 0.9087 - val_loss: 0.0346 - val_pr_auc: 0.8495 - val_roc_auc: 0.9138 - learning_rate: 0.0010\n",
            "Epoch 28/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0339 - pr_auc: 0.8429 - roc_auc: 0.9107 - val_loss: 0.0330 - val_pr_auc: 0.8557 - val_roc_auc: 0.9184 - learning_rate: 0.0010\n",
            "Epoch 29/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0335 - pr_auc: 0.8443 - roc_auc: 0.9125 - val_loss: 0.0350 - val_pr_auc: 0.8445 - val_roc_auc: 0.9120 - learning_rate: 0.0010\n",
            "Epoch 30/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0332 - pr_auc: 0.8428 - roc_auc: 0.9104 - val_loss: 0.0321 - val_pr_auc: 0.8514 - val_roc_auc: 0.9146 - learning_rate: 0.0010\n",
            "Epoch 31/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0326 - pr_auc: 0.8447 - roc_auc: 0.9119 - val_loss: 0.0328 - val_pr_auc: 0.8523 - val_roc_auc: 0.9157 - learning_rate: 0.0010\n",
            "Epoch 32/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0320 - pr_auc: 0.8471 - roc_auc: 0.9140 - val_loss: 0.0312 - val_pr_auc: 0.8542 - val_roc_auc: 0.9165 - learning_rate: 0.0010\n",
            "Epoch 33/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0315 - pr_auc: 0.8468 - roc_auc: 0.9123 - val_loss: 0.0313 - val_pr_auc: 0.8527 - val_roc_auc: 0.9156 - learning_rate: 0.0010\n",
            "Epoch 34/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0308 - pr_auc: 0.8512 - roc_auc: 0.9160 - val_loss: 0.0315 - val_pr_auc: 0.8502 - val_roc_auc: 0.9165 - learning_rate: 5.0000e-04\n",
            "Epoch 35/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0301 - pr_auc: 0.8527 - roc_auc: 0.9167 - val_loss: 0.0314 - val_pr_auc: 0.8501 - val_roc_auc: 0.9147 - learning_rate: 5.0000e-04\n",
            "Epoch 36/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0300 - pr_auc: 0.8517 - roc_auc: 0.9156 - val_loss: 0.0312 - val_pr_auc: 0.8523 - val_roc_auc: 0.9166 - learning_rate: 5.0000e-04\n",
            "Epoch 37/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0297 - pr_auc: 0.8533 - roc_auc: 0.9170 - val_loss: 0.0316 - val_pr_auc: 0.8503 - val_roc_auc: 0.9145 - learning_rate: 5.0000e-04\n",
            "Epoch 38/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0294 - pr_auc: 0.8541 - roc_auc: 0.9171 - val_loss: 0.0308 - val_pr_auc: 0.8533 - val_roc_auc: 0.9166 - learning_rate: 5.0000e-04\n",
            "Epoch 39/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0289 - pr_auc: 0.8564 - roc_auc: 0.9181 - val_loss: 0.0303 - val_pr_auc: 0.8510 - val_roc_auc: 0.9169 - learning_rate: 2.5000e-04\n",
            "Epoch 40/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0285 - pr_auc: 0.8581 - roc_auc: 0.9195 - val_loss: 0.0300 - val_pr_auc: 0.8527 - val_roc_auc: 0.9174 - learning_rate: 2.5000e-04\n",
            "Epoch 41/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0284 - pr_auc: 0.8578 - roc_auc: 0.9186 - val_loss: 0.0296 - val_pr_auc: 0.8528 - val_roc_auc: 0.9163 - learning_rate: 2.5000e-04\n",
            "Epoch 42/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0284 - pr_auc: 0.8575 - roc_auc: 0.9196 - val_loss: 0.0296 - val_pr_auc: 0.8539 - val_roc_auc: 0.9175 - learning_rate: 2.5000e-04\n",
            "Epoch 43/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0281 - pr_auc: 0.8596 - roc_auc: 0.9203 - val_loss: 0.0294 - val_pr_auc: 0.8567 - val_roc_auc: 0.9188 - learning_rate: 2.5000e-04\n",
            "Epoch 44/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0282 - pr_auc: 0.8576 - roc_auc: 0.9186 - val_loss: 0.0290 - val_pr_auc: 0.8543 - val_roc_auc: 0.9170 - learning_rate: 2.5000e-04\n",
            "Epoch 45/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0277 - pr_auc: 0.8614 - roc_auc: 0.9209 - val_loss: 0.0289 - val_pr_auc: 0.8549 - val_roc_auc: 0.9170 - learning_rate: 2.5000e-04\n",
            "Epoch 46/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0278 - pr_auc: 0.8583 - roc_auc: 0.9205 - val_loss: 0.0286 - val_pr_auc: 0.8571 - val_roc_auc: 0.9181 - learning_rate: 2.5000e-04\n",
            "Epoch 47/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0273 - pr_auc: 0.8621 - roc_auc: 0.9224 - val_loss: 0.0284 - val_pr_auc: 0.8571 - val_roc_auc: 0.9179 - learning_rate: 2.5000e-04\n",
            "Epoch 48/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0275 - pr_auc: 0.8603 - roc_auc: 0.9201 - val_loss: 0.0286 - val_pr_auc: 0.8559 - val_roc_auc: 0.9175 - learning_rate: 2.5000e-04\n",
            "Epoch 49/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0270 - pr_auc: 0.8639 - roc_auc: 0.9235 - val_loss: 0.0279 - val_pr_auc: 0.8602 - val_roc_auc: 0.9201 - learning_rate: 1.2500e-04\n",
            "Epoch 50/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0269 - pr_auc: 0.8637 - roc_auc: 0.9230 - val_loss: 0.0281 - val_pr_auc: 0.8569 - val_roc_auc: 0.9178 - learning_rate: 1.2500e-04\n",
            "Epoch 51/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0269 - pr_auc: 0.8631 - roc_auc: 0.9226 - val_loss: 0.0278 - val_pr_auc: 0.8592 - val_roc_auc: 0.9188 - learning_rate: 1.2500e-04\n",
            "Epoch 52/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0267 - pr_auc: 0.8649 - roc_auc: 0.9233 - val_loss: 0.0277 - val_pr_auc: 0.8600 - val_roc_auc: 0.9192 - learning_rate: 1.2500e-04\n",
            "Epoch 53/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0266 - pr_auc: 0.8655 - roc_auc: 0.9244 - val_loss: 0.0275 - val_pr_auc: 0.8590 - val_roc_auc: 0.9182 - learning_rate: 1.2500e-04\n",
            "Epoch 54/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0267 - pr_auc: 0.8639 - roc_auc: 0.9239 - val_loss: 0.0274 - val_pr_auc: 0.8597 - val_roc_auc: 0.9193 - learning_rate: 1.2500e-04\n",
            "Epoch 55/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0264 - pr_auc: 0.8668 - roc_auc: 0.9253 - val_loss: 0.0273 - val_pr_auc: 0.8618 - val_roc_auc: 0.9206 - learning_rate: 6.2500e-05\n",
            "Epoch 56/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0260 - pr_auc: 0.8694 - roc_auc: 0.9273 - val_loss: 0.0272 - val_pr_auc: 0.8626 - val_roc_auc: 0.9210 - learning_rate: 6.2500e-05\n",
            "Epoch 57/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0261 - pr_auc: 0.8681 - roc_auc: 0.9263 - val_loss: 0.0273 - val_pr_auc: 0.8610 - val_roc_auc: 0.9198 - learning_rate: 6.2500e-05\n",
            "Epoch 58/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0260 - pr_auc: 0.8691 - roc_auc: 0.9270 - val_loss: 0.0271 - val_pr_auc: 0.8620 - val_roc_auc: 0.9200 - learning_rate: 6.2500e-05\n",
            "Epoch 59/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0260 - pr_auc: 0.8685 - roc_auc: 0.9262 - val_loss: 0.0272 - val_pr_auc: 0.8616 - val_roc_auc: 0.9202 - learning_rate: 6.2500e-05\n",
            "Epoch 60/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0258 - pr_auc: 0.8680 - roc_auc: 0.9248 - val_loss: 0.0270 - val_pr_auc: 0.8631 - val_roc_auc: 0.9211 - learning_rate: 6.2500e-05\n",
            "Epoch 61/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0258 - pr_auc: 0.8688 - roc_auc: 0.9268 - val_loss: 0.0267 - val_pr_auc: 0.8633 - val_roc_auc: 0.9207 - learning_rate: 6.2500e-05\n",
            "Epoch 62/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0258 - pr_auc: 0.8702 - roc_auc: 0.9274 - val_loss: 0.0268 - val_pr_auc: 0.8621 - val_roc_auc: 0.9199 - learning_rate: 6.2500e-05\n",
            "Epoch 63/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0258 - pr_auc: 0.8691 - roc_auc: 0.9274 - val_loss: 0.0271 - val_pr_auc: 0.8618 - val_roc_auc: 0.9198 - learning_rate: 6.2500e-05\n",
            "Epoch 64/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0257 - pr_auc: 0.8708 - roc_auc: 0.9283 - val_loss: 0.0270 - val_pr_auc: 0.8615 - val_roc_auc: 0.9194 - learning_rate: 6.2500e-05\n",
            "Epoch 65/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0257 - pr_auc: 0.8704 - roc_auc: 0.9270 - val_loss: 0.0268 - val_pr_auc: 0.8623 - val_roc_auc: 0.9200 - learning_rate: 6.2500e-05\n",
            "Epoch 66/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0257 - pr_auc: 0.8697 - roc_auc: 0.9274 - val_loss: 0.0266 - val_pr_auc: 0.8651 - val_roc_auc: 0.9221 - learning_rate: 3.1250e-05\n",
            "Epoch 67/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0254 - pr_auc: 0.8709 - roc_auc: 0.9279 - val_loss: 0.0266 - val_pr_auc: 0.8644 - val_roc_auc: 0.9216 - learning_rate: 3.1250e-05\n",
            "Epoch 68/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0254 - pr_auc: 0.8718 - roc_auc: 0.9289 - val_loss: 0.0265 - val_pr_auc: 0.8650 - val_roc_auc: 0.9218 - learning_rate: 3.1250e-05\n",
            "Epoch 69/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0254 - pr_auc: 0.8714 - roc_auc: 0.9289 - val_loss: 0.0264 - val_pr_auc: 0.8650 - val_roc_auc: 0.9222 - learning_rate: 3.1250e-05\n",
            "Epoch 70/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0252 - pr_auc: 0.8735 - roc_auc: 0.9303 - val_loss: 0.0263 - val_pr_auc: 0.8657 - val_roc_auc: 0.9224 - learning_rate: 3.1250e-05\n",
            "Epoch 71/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0254 - pr_auc: 0.8718 - roc_auc: 0.9291 - val_loss: 0.0263 - val_pr_auc: 0.8651 - val_roc_auc: 0.9218 - learning_rate: 3.1250e-05\n",
            "Epoch 72/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0253 - pr_auc: 0.8716 - roc_auc: 0.9279 - val_loss: 0.0264 - val_pr_auc: 0.8645 - val_roc_auc: 0.9216 - learning_rate: 3.1250e-05\n",
            "Epoch 73/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0254 - pr_auc: 0.8715 - roc_auc: 0.9283 - val_loss: 0.0263 - val_pr_auc: 0.8643 - val_roc_auc: 0.9209 - learning_rate: 3.1250e-05\n",
            "Epoch 74/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0251 - pr_auc: 0.8739 - roc_auc: 0.9302 - val_loss: 0.0264 - val_pr_auc: 0.8653 - val_roc_auc: 0.9219 - learning_rate: 3.1250e-05\n",
            "Epoch 75/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0252 - pr_auc: 0.8726 - roc_auc: 0.9290 - val_loss: 0.0264 - val_pr_auc: 0.8651 - val_roc_auc: 0.9218 - learning_rate: 3.1250e-05\n",
            "Epoch 76/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0252 - pr_auc: 0.8725 - roc_auc: 0.9292 - val_loss: 0.0262 - val_pr_auc: 0.8661 - val_roc_auc: 0.9223 - learning_rate: 1.5625e-05\n",
            "Epoch 77/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0251 - pr_auc: 0.8736 - roc_auc: 0.9299 - val_loss: 0.0263 - val_pr_auc: 0.8661 - val_roc_auc: 0.9224 - learning_rate: 1.5625e-05\n",
            "Epoch 78/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0251 - pr_auc: 0.8740 - roc_auc: 0.9304 - val_loss: 0.0262 - val_pr_auc: 0.8662 - val_roc_auc: 0.9225 - learning_rate: 1.5625e-05\n",
            "Epoch 79/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0251 - pr_auc: 0.8725 - roc_auc: 0.9288 - val_loss: 0.0263 - val_pr_auc: 0.8658 - val_roc_auc: 0.9220 - learning_rate: 1.5625e-05\n",
            "Epoch 80/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0249 - pr_auc: 0.8752 - roc_auc: 0.9311 - val_loss: 0.0262 - val_pr_auc: 0.8658 - val_roc_auc: 0.9221 - learning_rate: 1.5625e-05\n",
            "Epoch 81/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0249 - pr_auc: 0.8753 - roc_auc: 0.9314 - val_loss: 0.0262 - val_pr_auc: 0.8661 - val_roc_auc: 0.9223 - learning_rate: 7.8125e-06\n",
            "Epoch 82/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0251 - pr_auc: 0.8736 - roc_auc: 0.9303 - val_loss: 0.0261 - val_pr_auc: 0.8662 - val_roc_auc: 0.9222 - learning_rate: 7.8125e-06\n",
            "Epoch 83/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0253 - pr_auc: 0.8730 - roc_auc: 0.9292 - val_loss: 0.0260 - val_pr_auc: 0.8664 - val_roc_auc: 0.9224 - learning_rate: 7.8125e-06\n",
            "Epoch 84/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0248 - pr_auc: 0.8775 - roc_auc: 0.9324 - val_loss: 0.0261 - val_pr_auc: 0.8664 - val_roc_auc: 0.9225 - learning_rate: 7.8125e-06\n",
            "Epoch 85/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0251 - pr_auc: 0.8719 - roc_auc: 0.9291 - val_loss: 0.0261 - val_pr_auc: 0.8664 - val_roc_auc: 0.9225 - learning_rate: 7.8125e-06\n",
            "Epoch 86/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0249 - pr_auc: 0.8741 - roc_auc: 0.9302 - val_loss: 0.0260 - val_pr_auc: 0.8668 - val_roc_auc: 0.9225 - learning_rate: 7.8125e-06\n",
            "Epoch 87/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0251 - pr_auc: 0.8743 - roc_auc: 0.9306 - val_loss: 0.0260 - val_pr_auc: 0.8668 - val_roc_auc: 0.9225 - learning_rate: 7.8125e-06\n",
            "Epoch 88/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0248 - pr_auc: 0.8754 - roc_auc: 0.9304 - val_loss: 0.0260 - val_pr_auc: 0.8667 - val_roc_auc: 0.9223 - learning_rate: 7.8125e-06\n",
            "Epoch 89/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0249 - pr_auc: 0.8737 - roc_auc: 0.9301 - val_loss: 0.0260 - val_pr_auc: 0.8667 - val_roc_auc: 0.9225 - learning_rate: 7.8125e-06\n",
            "Epoch 90/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0248 - pr_auc: 0.8742 - roc_auc: 0.9303 - val_loss: 0.0260 - val_pr_auc: 0.8670 - val_roc_auc: 0.9228 - learning_rate: 3.9063e-06\n",
            "Epoch 91/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0249 - pr_auc: 0.8751 - roc_auc: 0.9301 - val_loss: 0.0260 - val_pr_auc: 0.8670 - val_roc_auc: 0.9226 - learning_rate: 3.9063e-06\n",
            "Epoch 92/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0249 - pr_auc: 0.8740 - roc_auc: 0.9305 - val_loss: 0.0260 - val_pr_auc: 0.8669 - val_roc_auc: 0.9226 - learning_rate: 3.9063e-06\n",
            "Epoch 93/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0249 - pr_auc: 0.8754 - roc_auc: 0.9308 - val_loss: 0.0260 - val_pr_auc: 0.8671 - val_roc_auc: 0.9228 - learning_rate: 3.9063e-06\n",
            "Epoch 94/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0248 - pr_auc: 0.8760 - roc_auc: 0.9310 - val_loss: 0.0260 - val_pr_auc: 0.8669 - val_roc_auc: 0.9226 - learning_rate: 3.9063e-06\n",
            "Epoch 95/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0250 - pr_auc: 0.8735 - roc_auc: 0.9298 - val_loss: 0.0260 - val_pr_auc: 0.8673 - val_roc_auc: 0.9229 - learning_rate: 3.9063e-06\n",
            "Epoch 96/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0250 - pr_auc: 0.8735 - roc_auc: 0.9305 - val_loss: 0.0260 - val_pr_auc: 0.8671 - val_roc_auc: 0.9227 - learning_rate: 3.9063e-06\n",
            "Epoch 97/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0249 - pr_auc: 0.8750 - roc_auc: 0.9310 - val_loss: 0.0260 - val_pr_auc: 0.8671 - val_roc_auc: 0.9228 - learning_rate: 3.9063e-06\n",
            "Epoch 98/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0250 - pr_auc: 0.8737 - roc_auc: 0.9298 - val_loss: 0.0260 - val_pr_auc: 0.8671 - val_roc_auc: 0.9228 - learning_rate: 3.9063e-06\n",
            "Epoch 99/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0248 - pr_auc: 0.8758 - roc_auc: 0.9312 - val_loss: 0.0260 - val_pr_auc: 0.8668 - val_roc_auc: 0.9225 - learning_rate: 3.9063e-06\n",
            "Epoch 100/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0247 - pr_auc: 0.8757 - roc_auc: 0.9310 - val_loss: 0.0260 - val_pr_auc: 0.8668 - val_roc_auc: 0.9224 - learning_rate: 3.9063e-06\n",
            "Epoch 101/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0248 - pr_auc: 0.8762 - roc_auc: 0.9316 - val_loss: 0.0260 - val_pr_auc: 0.8667 - val_roc_auc: 0.9224 - learning_rate: 1.9531e-06\n",
            "Epoch 102/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0247 - pr_auc: 0.8763 - roc_auc: 0.9317 - val_loss: 0.0260 - val_pr_auc: 0.8667 - val_roc_auc: 0.9223 - learning_rate: 1.9531e-06\n",
            "Epoch 103/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0249 - pr_auc: 0.8738 - roc_auc: 0.9302 - val_loss: 0.0260 - val_pr_auc: 0.8666 - val_roc_auc: 0.9223 - learning_rate: 1.9531e-06\n",
            "Epoch 104/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0247 - pr_auc: 0.8770 - roc_auc: 0.9319 - val_loss: 0.0260 - val_pr_auc: 0.8666 - val_roc_auc: 0.9222 - learning_rate: 1.9531e-06\n",
            "Epoch 105/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0248 - pr_auc: 0.8758 - roc_auc: 0.9311 - val_loss: 0.0260 - val_pr_auc: 0.8666 - val_roc_auc: 0.9222 - learning_rate: 1.9531e-06\n",
            "Epoch 106/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0248 - pr_auc: 0.8761 - roc_auc: 0.9313 - val_loss: 0.0260 - val_pr_auc: 0.8666 - val_roc_auc: 0.9223 - learning_rate: 1.0000e-06\n",
            "Epoch 107/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0247 - pr_auc: 0.8761 - roc_auc: 0.9319 - val_loss: 0.0260 - val_pr_auc: 0.8665 - val_roc_auc: 0.9222 - learning_rate: 1.0000e-06\n",
            "Epoch 108/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0248 - pr_auc: 0.8745 - roc_auc: 0.9308 - val_loss: 0.0260 - val_pr_auc: 0.8668 - val_roc_auc: 0.9223 - learning_rate: 1.0000e-06\n",
            "Epoch 109/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0250 - pr_auc: 0.8738 - roc_auc: 0.9301 - val_loss: 0.0260 - val_pr_auc: 0.8666 - val_roc_auc: 0.9222 - learning_rate: 1.0000e-06\n",
            "Epoch 110/120\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0250 - pr_auc: 0.8748 - roc_auc: 0.9311 - val_loss: 0.0260 - val_pr_auc: 0.8665 - val_roc_auc: 0.9222 - learning_rate: 1.0000e-06\n",
            "Residual NN trained in 110 epochs\n"
          ]
        }
      ],
      "source": [
        "# Compile residual network with focal loss\n",
        "residual_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=focal_loss,\n",
        "    metrics=[keras.metrics.AUC(name='roc_auc', curve='ROC'), keras.metrics.AUC(name='pr_auc', curve='PR')]\n",
        ")\n",
        "\n",
        "# Early stopping with longer patience (15 epochs) since residual networks can train longer\n",
        "residual_early_stop = keras.callbacks.EarlyStopping(monitor='val_roc_auc', mode='max', patience=15, restore_best_weights=True)\n",
        "residual_lr_reduce = keras.callbacks.ReduceLROnPlateau(monitor='val_roc_auc', mode='max', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "# Train with more epochs (120) since residual connections allow deeper training\n",
        "residual_history = residual_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=120,\n",
        "    batch_size=512,\n",
        "    callbacks=[residual_early_stop, residual_lr_reduce],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f'Residual NN trained in {len(residual_history.history[\"roc_auc\"])} epochs')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Threshold Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal threshold: 0.3520\n"
          ]
        }
      ],
      "source": [
        "# Optimize threshold for residual network\n",
        "residual_train_scores = residual_model.predict(X_train, verbose=0).ravel()\n",
        "\n",
        "prec, rec, thresholds = precision_recall_curve(y_train, residual_train_scores)\n",
        "f1_scores = 2 * prec * rec / (prec + rec + 1e-9)\n",
        "best_idx = np.nanargmax(f1_scores)\n",
        "residual_optimal_threshold = thresholds[max(0, best_idx - 1)] if len(thresholds) > 0 else 0.5\n",
        "\n",
        "print(f'Optimal threshold: {residual_optimal_threshold:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Metrics:\n",
            "  ROC-AUC: 0.9369, PR-AUC: 0.8846\n",
            "  F1: 0.8180, Precision: 0.9474, Recall: 0.7197\n",
            "  Specificity: 0.9889\n",
            "\n",
            "Test Metrics:\n",
            "  ROC-AUC: 0.9306, PR-AUC: 0.8764\n",
            "  F1: 0.8094, Precision: 0.9273, Recall: 0.7180\n",
            "  Specificity: 0.9843\n"
          ]
        }
      ],
      "source": [
        "# Evaluate residual network\n",
        "residual_train_pred = (residual_train_scores >= residual_optimal_threshold).astype(int)\n",
        "residual_test_scores = residual_model.predict(X_test, verbose=0).ravel()\n",
        "residual_test_pred = (residual_test_scores >= residual_optimal_threshold).astype(int)\n",
        "\n",
        "residual_train_metrics = {\n",
        "    'roc_auc': roc_auc_score(y_train, residual_train_scores),\n",
        "    'pr_auc': average_precision_score(y_train, residual_train_scores),\n",
        "    'f1': f1_score(y_train, residual_train_pred),\n",
        "    'precision': precision_score(y_train, residual_train_pred),\n",
        "    'recall': recall_score(y_train, residual_train_pred)\n",
        "}\n",
        "\n",
        "residual_test_metrics = {\n",
        "    'roc_auc': roc_auc_score(y_test, residual_test_scores),\n",
        "    'pr_auc': average_precision_score(y_test, residual_test_scores),\n",
        "    'f1': f1_score(y_test, residual_test_pred),\n",
        "    'precision': precision_score(y_test, residual_test_pred),\n",
        "    'recall': recall_score(y_test, residual_test_pred),\n",
        "    'threshold': residual_optimal_threshold\n",
        "}\n",
        "\n",
        "residual_train_cm = confusion_matrix(y_train, residual_train_pred)\n",
        "residual_test_cm = confusion_matrix(y_test, residual_test_pred)\n",
        "residual_train_specificity = residual_train_cm[0, 0] / (residual_train_cm[0, 0] + residual_train_cm[0, 1] + 1e-9)\n",
        "residual_test_specificity = residual_test_cm[0, 0] / (residual_test_cm[0, 0] + residual_test_cm[0, 1] + 1e-9)\n",
        "\n",
        "print('Training Metrics:')\n",
        "print(f\"  ROC-AUC: {residual_train_metrics['roc_auc']:.4f}, PR-AUC: {residual_train_metrics['pr_auc']:.4f}\")\n",
        "print(f\"  F1: {residual_train_metrics['f1']:.4f}, Precision: {residual_train_metrics['precision']:.4f}, Recall: {residual_train_metrics['recall']:.4f}\")\n",
        "print(f\"  Specificity: {residual_train_specificity:.4f}\")\n",
        "\n",
        "print('\\nTest Metrics:')\n",
        "print(f\"  ROC-AUC: {residual_test_metrics['roc_auc']:.4f}, PR-AUC: {residual_test_metrics['pr_auc']:.4f}\")\n",
        "print(f\"  F1: {residual_test_metrics['f1']:.4f}, Precision: {residual_test_metrics['precision']:.4f}, Recall: {residual_test_metrics['recall']:.4f}\")\n",
        "print(f\"  Specificity: {residual_test_specificity:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: residual_roc.png\n"
          ]
        }
      ],
      "source": [
        "fpr_train, tpr_train, _ = roc_curve(y_train, residual_train_scores)\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, residual_test_scores)\n",
        "auc_train = auc(fpr_train, tpr_train)\n",
        "auc_test = auc(fpr_test, tpr_test)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.plot(fpr_train, tpr_train, label=f'Train (AUC = {auc_train:.4f})', linewidth=2, linestyle='--')\n",
        "ax.plot(fpr_test, tpr_test, label=f'Test (AUC = {auc_test:.4f})', linewidth=2)\n",
        "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5, label='Random')\n",
        "ax.set_xlabel('False Positive Rate', fontsize=11)\n",
        "ax.set_ylabel('True Positive Rate', fontsize=11)\n",
        "ax.set_title('Residual Neural Network - ROC Curve', fontsize=12, fontweight='bold')\n",
        "ax.legend(loc='lower right')\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'residual_roc.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: residual_roc.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: residual_cm.png\n"
          ]
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "sns.heatmap(residual_train_cm, annot=True, fmt='d', cmap='Blues', ax=ax1, cbar=False)\n",
        "ax1.set_title('Training Set', fontsize=11, fontweight='bold')\n",
        "ax1.set_xlabel('Predicted')\n",
        "ax1.set_ylabel('Actual')\n",
        "\n",
        "sns.heatmap(residual_test_cm, annot=True, fmt='d', cmap='Blues', ax=ax2, cbar=False)\n",
        "ax2.set_title('Test Set', fontsize=11, fontweight='bold')\n",
        "ax2.set_xlabel('Predicted')\n",
        "ax2.set_ylabel('Actual')\n",
        "\n",
        "plt.suptitle('Residual Neural Network - Confusion Matrix', fontsize=12, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'residual_cm.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: residual_cm.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: residual_pr.png\n"
          ]
        }
      ],
      "source": [
        "prec_train, rec_train, _ = precision_recall_curve(y_train, residual_train_scores)\n",
        "prec_test, rec_test, _ = precision_recall_curve(y_test, residual_test_scores)\n",
        "pr_auc_train = average_precision_score(y_train, residual_train_scores)\n",
        "pr_auc_test = average_precision_score(y_test, residual_test_scores)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.plot(rec_train, prec_train, label=f'Train (AUC = {pr_auc_train:.4f})', linewidth=2, linestyle='--')\n",
        "ax.plot(rec_test, prec_test, label=f'Test (AUC = {pr_auc_test:.4f})', linewidth=2)\n",
        "ax.set_xlabel('Recall', fontsize=11)\n",
        "ax.set_ylabel('Precision', fontsize=11)\n",
        "ax.set_title('Residual Neural Network - Precision-Recall Curve', fontsize=12, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'residual_pr.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: residual_pr.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 5: Multi-Scale Ensemble\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Base Models Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xgb_deep trained\n",
            "xgb_shallow trained\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-4 (_readerthread):\n",
            "Traceback (most recent call last):\n",
            "  File \"d:\\Conda\\envs\\final_last\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"d:\\Conda\\envs\\final_last\\lib\\threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"d:\\Conda\\envs\\final_last\\lib\\subprocess.py\", line 1515, in _readerthread\n",
            "    buffer.append(fh.read())\n",
            "  File \"d:\\Conda\\envs\\final_last\\lib\\codecs.py\", line 322, in decode\n",
            "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
            "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xce in position 4: invalid continuation byte\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lgbm_fast trained\n",
            "catboost_robust trained\n"
          ]
        }
      ],
      "source": [
        "# Base Models for Ensemble: Train multiple gradient boosting models with different configurations\n",
        "# Why multiple models? Different algorithms and hyperparameters capture different patterns\n",
        "# Ensemble diversity improves final performance by combining complementary predictions\n",
        "\n",
        "# XGBoost Deep: Deep trees (depth=8) for complex patterns, slower but more powerful\n",
        "xgb_deep = XGBClassifier(\n",
        "    max_depth=8, learning_rate=0.02, n_estimators=500,\n",
        "    subsample=0.8, colsample_bytree=0.8, scale_pos_weight=scale_pos_weight,\n",
        "    random_state=42, tree_method='hist', eval_metric='auc'\n",
        ")\n",
        "\n",
        "# XGBoost Shallow: Shallow trees (depth=3) for simpler patterns, faster training\n",
        "xgb_shallow = XGBClassifier(\n",
        "    max_depth=3, learning_rate=0.05, n_estimators=300,\n",
        "    subsample=0.9, colsample_bytree=0.9, scale_pos_weight=scale_pos_weight,\n",
        "    random_state=42, tree_method='hist', eval_metric='auc'\n",
        ")\n",
        "\n",
        "# LightGBM: Different algorithm (leaf-wise growth vs level-wise), often faster\n",
        "lgbm_fast = LGBMClassifier(\n",
        "    max_depth=6, learning_rate=0.03, n_estimators=400,\n",
        "    subsample=0.85, colsample_bytree=0.85, scale_pos_weight=scale_pos_weight,\n",
        "    random_state=42, verbose=-1\n",
        ")\n",
        "\n",
        "# CatBoost: Handles categorical features well, robust to overfitting\n",
        "catboost_robust = CatBoostClassifier(\n",
        "    depth=7, learning_rate=0.025, iterations=450,\n",
        "    subsample=0.8, colsample_bylevel=0.8, scale_pos_weight=scale_pos_weight,\n",
        "    random_state=42, verbose=False\n",
        ")\n",
        "\n",
        "base_models = [\n",
        "    ('xgb_deep', xgb_deep),\n",
        "    ('xgb_shallow', xgb_shallow),\n",
        "    ('lgbm_fast', lgbm_fast),\n",
        "    ('catboost_robust', catboost_robust)\n",
        "]\n",
        "\n",
        "# Train all base models on full training set\n",
        "# These will be used later in cross-validation to generate meta-features\n",
        "for name, base_model in base_models:\n",
        "    base_model.fit(X_train, y_train)\n",
        "    print(f'{name} trained')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Meta-Learner Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Meta-learner training data shape: (26064, 5)\n"
          ]
        }
      ],
      "source": [
        "# ENSEMBLE STACKING: Train meta-learner on predictions from base models\n",
        "# Stacking works by training base models on different folds, then using their predictions as features for meta-learner\n",
        "# This prevents data leakage: meta-learner never sees predictions from models trained on same data\n",
        "\n",
        "# Initialize meta-feature arrays\n",
        "# n_base_models + 1: 4 gradient boosting models + 1 neural network = 5 base models\n",
        "n_base_models = len(base_models) + 1\n",
        "meta_train = np.zeros((X_train.shape[0], n_base_models))  # One column per base model\n",
        "meta_test = np.zeros((X_test.shape[0], n_base_models))\n",
        "\n",
        "# Separate arrays for neural network predictions (will be added to meta_train/meta_test later)\n",
        "nn_meta_train = np.zeros(X_train.shape[0])\n",
        "nn_meta_test = np.zeros(X_test.shape[0])\n",
        "\n",
        "# Cross-validation loop: For each fold, train base models on training fold, predict on validation fold\n",
        "# This ensures meta-learner training data (meta_train) has unbiased predictions\n",
        "for train_idx, val_idx in cv.split(X_train, y_train):\n",
        "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    # Train each gradient boosting model on current fold\n",
        "    for model_idx, (name, base_model) in enumerate(base_models):\n",
        "        # Create fresh copy of model with same hyperparameters\n",
        "        model_copy = type(base_model)(**base_model.get_params())\n",
        "        # Train on training fold only\n",
        "        model_copy.fit(X_train_fold, y_train_fold)\n",
        "        # Predict on validation fold (these become meta-features for meta-learner)\n",
        "        meta_train[val_idx, model_idx] = model_copy.predict_proba(X_val_fold)[:, 1]\n",
        "        # Predict on test set and average across folds (reduces variance)\n",
        "        meta_test[:, model_idx] += model_copy.predict_proba(X_test)[:, 1] / cv.n_splits\n",
        "\n",
        "    # Train neural network base model on current fold\n",
        "    # Neural network is trained per-fold to ensure diversity and prevent overfitting\n",
        "    nn_model_fold = keras.Sequential([\n",
        "        layers.Dense(512, kernel_regularizer=regularizers.l2(1e-4), input_shape=(X_train_fold.shape[1],)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('swish'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(256, kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('swish'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(128, kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('swish'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(64, kernel_regularizer=regularizers.l2(1e-4)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('swish'),\n",
        "        layers.Dropout(0.15),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    nn_model_fold.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=focal_loss,\n",
        "        metrics=[keras.metrics.AUC(name='roc_auc', curve='ROC'), keras.metrics.AUC(name='pr_auc', curve='PR')]\n",
        "    )\n",
        "    \n",
        "    fold_callbacks = [\n",
        "        keras.callbacks.EarlyStopping(monitor='val_roc_auc', mode='max', patience=8, restore_best_weights=True, verbose=0),\n",
        "        keras.callbacks.ReduceLROnPlateau(monitor='val_roc_auc', mode='max', factor=0.5, patience=4, min_lr=1e-6, verbose=0)\n",
        "    ]\n",
        "    \n",
        "    # Train neural network on training fold\n",
        "    nn_model_fold.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        validation_data=(X_val_fold, y_val_fold),\n",
        "        epochs=80,\n",
        "        batch_size=512,\n",
        "        callbacks=fold_callbacks,\n",
        "        verbose=0\n",
        "    )\n",
        "    \n",
        "    # Get predictions from neural network for validation fold and test set\n",
        "    nn_meta_train[val_idx] = nn_model_fold.predict(X_val_fold, verbose=0).ravel()\n",
        "    nn_meta_test += nn_model_fold.predict(X_test, verbose=0).ravel() / cv.n_splits\n",
        "\n",
        "# Add neural network predictions as the 5th base model\n",
        "meta_train[:, len(base_models)] = nn_meta_train\n",
        "meta_test[:, len(base_models)] = nn_meta_test\n",
        "\n",
        "print(f'Meta-learner training data shape: {meta_train.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Meta-learner trained in 38 epochs\n"
          ]
        }
      ],
      "source": [
        "# META-LEARNER ARCHITECTURE: Small neural network that learns to combine base model predictions\n",
        "# Input: 5 predictions (one from each base model) - these are the meta-features\n",
        "# Output: Final ensemble prediction\n",
        "# Why small network? Meta-features are already rich (predictions from trained models)\n",
        "# Small network prevents overfitting and learns optimal combination weights\n",
        "\n",
        "meta_input = layers.Input(shape=(n_base_models,))\n",
        "meta_x = layers.Dense(32, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(meta_input)\n",
        "meta_x = layers.BatchNormalization()(meta_x)\n",
        "meta_x = layers.Dropout(0.2)(meta_x)\n",
        "meta_x = layers.Dense(16, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(meta_x)\n",
        "meta_x = layers.BatchNormalization()(meta_x)\n",
        "meta_output = layers.Dense(1, activation='sigmoid')(meta_x)\n",
        "\n",
        "meta_model = keras.Model(inputs=meta_input, outputs=meta_output)\n",
        "\n",
        "# Compile meta-learner with focal loss\n",
        "meta_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=focal_loss,\n",
        "    metrics=[keras.metrics.AUC(name='roc_auc', curve='ROC'), keras.metrics.AUC(name='pr_auc', curve='PR')]\n",
        ")\n",
        "\n",
        "meta_early_stop = keras.callbacks.EarlyStopping(monitor='val_roc_auc', mode='max', patience=10, restore_best_weights=True)\n",
        "meta_lr_reduce = keras.callbacks.ReduceLROnPlateau(monitor='val_roc_auc', mode='max', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "# Train meta-learner on meta-features (base model predictions)\n",
        "# meta_train contains predictions from base models trained on different folds\n",
        "# This teaches meta-learner how to best combine the base model predictions\n",
        "meta_history = meta_model.fit(\n",
        "    meta_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=80,\n",
        "    batch_size=256,\n",
        "    callbacks=[meta_early_stop, meta_lr_reduce],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(f'Meta-learner trained in {len(meta_history.history[\"roc_auc\"])} epochs')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal threshold: 0.3620\n"
          ]
        }
      ],
      "source": [
        "# Optimize threshold for ensemble meta-learner\n",
        "ensemble_train_scores = meta_model.predict(meta_train, verbose=0).ravel()\n",
        "\n",
        "prec, rec, thresholds = precision_recall_curve(y_train, ensemble_train_scores)\n",
        "f1_scores = 2 * prec * rec / (prec + rec + 1e-9)\n",
        "best_idx = np.nanargmax(f1_scores)\n",
        "ensemble_optimal_threshold = thresholds[max(0, best_idx - 1)] if len(thresholds) > 0 else 0.5\n",
        "\n",
        "print(f'Optimal threshold: {ensemble_optimal_threshold:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Metrics:\n",
            "  ROC-AUC: 0.9484, PR-AUC: 0.9040\n",
            "  F1: 0.8353, Precision: 0.9508, Recall: 0.7448\n",
            "  Specificity: 0.9893\n",
            "\n",
            "Test Metrics:\n",
            "  ROC-AUC: 0.9539, PR-AUC: 0.9137\n",
            "  F1: 0.8397, Precision: 0.9636, Recall: 0.7440\n",
            "  Specificity: 0.9921\n"
          ]
        }
      ],
      "source": [
        "# Evaluate ensemble meta-learner performance\n",
        "ensemble_train_pred = (ensemble_train_scores >= ensemble_optimal_threshold).astype(int)\n",
        "ensemble_test_scores = meta_model.predict(meta_test, verbose=0).ravel()\n",
        "ensemble_test_pred = (ensemble_test_scores >= ensemble_optimal_threshold).astype(int)\n",
        "\n",
        "ensemble_train_metrics = {\n",
        "    'roc_auc': roc_auc_score(y_train, ensemble_train_scores),\n",
        "    'pr_auc': average_precision_score(y_train, ensemble_train_scores),\n",
        "    'f1': f1_score(y_train, ensemble_train_pred),\n",
        "    'precision': precision_score(y_train, ensemble_train_pred),\n",
        "    'recall': recall_score(y_train, ensemble_train_pred)\n",
        "}\n",
        "\n",
        "ensemble_test_metrics = {\n",
        "    'roc_auc': roc_auc_score(y_test, ensemble_test_scores),\n",
        "    'pr_auc': average_precision_score(y_test, ensemble_test_scores),\n",
        "    'f1': f1_score(y_test, ensemble_test_pred),\n",
        "    'precision': precision_score(y_test, ensemble_test_pred),\n",
        "    'recall': recall_score(y_test, ensemble_test_pred),\n",
        "    'threshold': ensemble_optimal_threshold\n",
        "}\n",
        "\n",
        "ensemble_train_cm = confusion_matrix(y_train, ensemble_train_pred)\n",
        "ensemble_test_cm = confusion_matrix(y_test, ensemble_test_pred)\n",
        "ensemble_train_specificity = ensemble_train_cm[0, 0] / (ensemble_train_cm[0, 0] + ensemble_train_cm[0, 1] + 1e-9)\n",
        "ensemble_test_specificity = ensemble_test_cm[0, 0] / (ensemble_test_cm[0, 0] + ensemble_test_cm[0, 1] + 1e-9)\n",
        "\n",
        "print('Training Metrics:')\n",
        "print(f\"  ROC-AUC: {ensemble_train_metrics['roc_auc']:.4f}, PR-AUC: {ensemble_train_metrics['pr_auc']:.4f}\")\n",
        "print(f\"  F1: {ensemble_train_metrics['f1']:.4f}, Precision: {ensemble_train_metrics['precision']:.4f}, Recall: {ensemble_train_metrics['recall']:.4f}\")\n",
        "print(f\"  Specificity: {ensemble_train_specificity:.4f}\")\n",
        "\n",
        "print('\\nTest Metrics:')\n",
        "print(f\"  ROC-AUC: {ensemble_test_metrics['roc_auc']:.4f}, PR-AUC: {ensemble_test_metrics['pr_auc']:.4f}\")\n",
        "print(f\"  F1: {ensemble_test_metrics['f1']:.4f}, Precision: {ensemble_test_metrics['precision']:.4f}, Recall: {ensemble_test_metrics['recall']:.4f}\")\n",
        "print(f\"  Specificity: {ensemble_test_specificity:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: ensemble_roc.png\n"
          ]
        }
      ],
      "source": [
        "fpr_train, tpr_train, _ = roc_curve(y_train, ensemble_train_scores)\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, ensemble_test_scores)\n",
        "auc_train = auc(fpr_train, tpr_train)\n",
        "auc_test = auc(fpr_test, tpr_test)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.plot(fpr_train, tpr_train, label=f'Train (AUC = {auc_train:.4f})', linewidth=2, linestyle='--')\n",
        "ax.plot(fpr_test, tpr_test, label=f'Test (AUC = {auc_test:.4f})', linewidth=2)\n",
        "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5, label='Random')\n",
        "ax.set_xlabel('False Positive Rate', fontsize=11)\n",
        "ax.set_ylabel('True Positive Rate', fontsize=11)\n",
        "ax.set_title('Multi-Scale Ensemble - ROC Curve', fontsize=12, fontweight='bold')\n",
        "ax.legend(loc='lower right')\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'ensemble_roc.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: ensemble_roc.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: ensemble_cm.png\n"
          ]
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "sns.heatmap(ensemble_train_cm, annot=True, fmt='d', cmap='Blues', ax=ax1, cbar=False)\n",
        "ax1.set_title('Training Set', fontsize=11, fontweight='bold')\n",
        "ax1.set_xlabel('Predicted')\n",
        "ax1.set_ylabel('Actual')\n",
        "\n",
        "sns.heatmap(ensemble_test_cm, annot=True, fmt='d', cmap='Blues', ax=ax2, cbar=False)\n",
        "ax2.set_title('Test Set', fontsize=11, fontweight='bold')\n",
        "ax2.set_xlabel('Predicted')\n",
        "ax2.set_ylabel('Actual')\n",
        "\n",
        "plt.suptitle('Multi-Scale Ensemble - Confusion Matrix', fontsize=12, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'ensemble_cm.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: ensemble_cm.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: ensemble_pr.png\n"
          ]
        }
      ],
      "source": [
        "prec_train, rec_train, _ = precision_recall_curve(y_train, ensemble_train_scores)\n",
        "prec_test, rec_test, _ = precision_recall_curve(y_test, ensemble_test_scores)\n",
        "pr_auc_train = average_precision_score(y_train, ensemble_train_scores)\n",
        "pr_auc_test = average_precision_score(y_test, ensemble_test_scores)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.plot(rec_train, prec_train, label=f'Train (AUC = {pr_auc_train:.4f})', linewidth=2, linestyle='--')\n",
        "ax.plot(rec_test, prec_test, label=f'Test (AUC = {pr_auc_test:.4f})', linewidth=2)\n",
        "ax.set_xlabel('Recall', fontsize=11)\n",
        "ax.set_ylabel('Precision', fontsize=11)\n",
        "ax.set_title('Multi-Scale Ensemble - Precision-Recall Curve', fontsize=12, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'ensemble_pr.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: ensemble_pr.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Comparison\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Performance Ranking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  Model  Test ROC-AUC  Test PR-AUC  Test F1  Test Precision  Test Recall  Optimal Threshold\n",
            "   Multi-Scale Ensemble      0.953922     0.913679 0.839683        0.963570     0.744023           0.362014\n",
            "Residual Neural Network      0.930603     0.876362 0.809354        0.927339     0.718003           0.351998\n",
            "   Deep & Cross Network      0.925147     0.865276 0.793349        0.907609     0.704641           0.307599\n",
            "            Pure TabNet      0.921846     0.860787 0.794575        0.917972     0.700422           0.767038\n",
            "     TabNet + Tokenizer      0.919736     0.846213 0.774676        0.878680     0.692686           0.706486\n"
          ]
        }
      ],
      "source": [
        "# Compare all neural network models across multiple metrics\n",
        "# Ensemble typically performs best by combining strengths of individual models\n",
        "comparison_data = {\n",
        "    'Model': ['Pure TabNet', 'TabNet + Tokenizer', 'Deep & Cross Network', 'Residual Neural Network', 'Multi-Scale Ensemble'],\n",
        "    'Test ROC-AUC': [\n",
        "        tabnet_pure_test_metrics['roc_auc'],\n",
        "        tabnet_tokenizer_test_metrics['roc_auc'],\n",
        "        dcn_test_metrics['roc_auc'],\n",
        "        residual_test_metrics['roc_auc'],\n",
        "        ensemble_test_metrics['roc_auc']\n",
        "    ],\n",
        "    'Test PR-AUC': [\n",
        "        tabnet_pure_test_metrics['pr_auc'],\n",
        "        tabnet_tokenizer_test_metrics['pr_auc'],\n",
        "        dcn_test_metrics['pr_auc'],\n",
        "        residual_test_metrics['pr_auc'],\n",
        "        ensemble_test_metrics['pr_auc']\n",
        "    ],\n",
        "    'Test F1': [\n",
        "        tabnet_pure_test_metrics['f1'],\n",
        "        tabnet_tokenizer_test_metrics['f1'],\n",
        "        dcn_test_metrics['f1'],\n",
        "        residual_test_metrics['f1'],\n",
        "        ensemble_test_metrics['f1']\n",
        "    ],\n",
        "    'Test Precision': [\n",
        "        tabnet_pure_test_metrics['precision'],\n",
        "        tabnet_tokenizer_test_metrics['precision'],\n",
        "        dcn_test_metrics['precision'],\n",
        "        residual_test_metrics['precision'],\n",
        "        ensemble_test_metrics['precision']\n",
        "    ],\n",
        "    'Test Recall': [\n",
        "        tabnet_pure_test_metrics['recall'],\n",
        "        tabnet_tokenizer_test_metrics['recall'],\n",
        "        dcn_test_metrics['recall'],\n",
        "        residual_test_metrics['recall'],\n",
        "        ensemble_test_metrics['recall']\n",
        "    ],\n",
        "    'Optimal Threshold': [\n",
        "        tabnet_pure_optimal_threshold,\n",
        "        tabnet_tokenizer_optimal_threshold,\n",
        "        dcn_optimal_threshold,\n",
        "        residual_optimal_threshold,\n",
        "        ensemble_optimal_threshold\n",
        "    ]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "# Sort by Test ROC-AUC to rank models\n",
        "comparison_df = comparison_df.sort_values('Test ROC-AUC', ascending=False)\n",
        "comparison_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(comparison_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROC Curves Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: roc_curves_comparison.png\n"
          ]
        }
      ],
      "source": [
        "tabnet_pure_fpr, tabnet_pure_tpr, _ = roc_curve(y_test, tabnet_pure_test_scores)\n",
        "tabnet_tokenizer_fpr, tabnet_tokenizer_tpr, _ = roc_curve(y_test, tabnet_tokenizer_test_scores)\n",
        "dcn_fpr, dcn_tpr, _ = roc_curve(y_test, dcn_test_scores)\n",
        "residual_fpr, residual_tpr, _ = roc_curve(y_test, residual_test_scores)\n",
        "ensemble_fpr, ensemble_tpr, _ = roc_curve(y_test, ensemble_test_scores)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 7))\n",
        "ax.plot(tabnet_pure_fpr, tabnet_pure_tpr, label=f'Pure TabNet (AUC = {tabnet_pure_test_metrics[\"roc_auc\"]:.4f})', linewidth=2.5, color='#2E86AB')\n",
        "ax.plot(tabnet_tokenizer_fpr, tabnet_tokenizer_tpr, label=f'TabNet + Tokenizer (AUC = {tabnet_tokenizer_test_metrics[\"roc_auc\"]:.4f})', linewidth=2.5, color='#A23B72')\n",
        "ax.plot(dcn_fpr, dcn_tpr, label=f'DCN (AUC = {dcn_test_metrics[\"roc_auc\"]:.4f})', linewidth=2.5, color='#F18F01')\n",
        "ax.plot(residual_fpr, residual_tpr, label=f'Residual NN (AUC = {residual_test_metrics[\"roc_auc\"]:.4f})', linewidth=2.5, color='#6A994E')\n",
        "ax.plot(ensemble_fpr, ensemble_tpr, label=f'Multi-Scale Ensemble (AUC = {ensemble_test_metrics[\"roc_auc\"]:.4f})', linewidth=2.5, color='#C77DFF')\n",
        "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5, label='Random Classifier')\n",
        "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
        "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
        "ax.set_title('ROC Curves Comparison - Test Set', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='lower right', fontsize=10)\n",
        "ax.grid(alpha=0.3)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_ylim([0, 1])\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(images_dir, 'roc_curves_comparison.png'), dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print('Saved: roc_curves_comparison.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully saved model at d:\\FINAL PROJECT\\models\\tabnet_pure_neural.zip.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully saved model at d:\\FINAL PROJECT\\models\\tabnet_tokenizer_neural.zip.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved all model results and artifacts\n"
          ]
        }
      ],
      "source": [
        "# Prepare results dictionary with all model metrics and performance data\n",
        "all_results = {\n",
        "    'tabnet_pure': {\n",
        "        'train_metrics': {k: float(v) for k, v in tabnet_pure_train_metrics.items()},\n",
        "        'test_metrics': {k: float(v) for k, v in tabnet_pure_test_metrics.items()},\n",
        "        'train_confusion': tabnet_pure_train_cm.tolist(),\n",
        "        'test_confusion': tabnet_pure_test_cm.tolist(),\n",
        "        'train_specificity': float(tabnet_pure_train_specificity),\n",
        "        'test_specificity': float(tabnet_pure_test_specificity),\n",
        "        'optimal_threshold': float(tabnet_pure_optimal_threshold)\n",
        "    },\n",
        "    'tabnet_tokenizer': {\n",
        "        'train_metrics': {k: float(v) for k, v in tabnet_tokenizer_train_metrics.items()},\n",
        "        'test_metrics': {k: float(v) for k, v in tabnet_tokenizer_test_metrics.items()},\n",
        "        'train_confusion': tabnet_tokenizer_train_cm.tolist(),\n",
        "        'test_confusion': tabnet_tokenizer_test_cm.tolist(),\n",
        "        'train_specificity': float(tabnet_tokenizer_train_specificity),\n",
        "        'test_specificity': float(tabnet_tokenizer_test_specificity),\n",
        "        'optimal_threshold': float(tabnet_tokenizer_optimal_threshold)\n",
        "    },\n",
        "    'dcn': {\n",
        "        'train_metrics': {k: float(v) for k, v in dcn_train_metrics.items()},\n",
        "        'test_metrics': {k: float(v) for k, v in dcn_test_metrics.items()},\n",
        "        'train_confusion': dcn_train_cm.tolist(),\n",
        "        'test_confusion': dcn_test_cm.tolist(),\n",
        "        'train_specificity': float(dcn_train_specificity),\n",
        "        'test_specificity': float(dcn_test_specificity),\n",
        "        'optimal_threshold': float(dcn_optimal_threshold)\n",
        "    },\n",
        "    'residual': {\n",
        "        'train_metrics': {k: float(v) for k, v in residual_train_metrics.items()},\n",
        "        'test_metrics': {k: float(v) for k, v in residual_test_metrics.items()},\n",
        "        'train_confusion': residual_train_cm.tolist(),\n",
        "        'test_confusion': residual_test_cm.tolist(),\n",
        "        'train_specificity': float(residual_train_specificity),\n",
        "        'test_specificity': float(residual_test_specificity),\n",
        "        'optimal_threshold': float(residual_optimal_threshold)\n",
        "    },\n",
        "    'ensemble': {\n",
        "        'train_metrics': {k: float(v) for k, v in ensemble_train_metrics.items()},\n",
        "        'test_metrics': {k: float(v) for k, v in ensemble_test_metrics.items()},\n",
        "        'train_confusion': ensemble_train_cm.tolist(),\n",
        "        'test_confusion': ensemble_test_cm.tolist(),\n",
        "        'train_specificity': float(ensemble_train_specificity),\n",
        "        'test_specificity': float(ensemble_test_specificity),\n",
        "        'optimal_threshold': float(ensemble_optimal_threshold)\n",
        "    },\n",
        "    'comparison': json.loads(comparison_df.to_json(orient='records'))\n",
        "}\n",
        "\n",
        "# Save metrics to JSON file for analysis\n",
        "with open(os.path.join(MODELS_DIR, 'neural_network_results.json'), 'w') as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "\n",
        "# Save trained models in their native formats\n",
        "# TabNet models use .zip format (PyTorch-based)\n",
        "tabnet_pure.save_model(os.path.join(MODELS_DIR, 'tabnet_pure_neural.zip'))\n",
        "tabnet_tokenizer.save_model(os.path.join(MODELS_DIR, 'tabnet_tokenizer_neural.zip'))\n",
        "# Keras models use .h5 format (HDF5)\n",
        "dcn_model.save(os.path.join(MODELS_DIR, 'dcn_neural.h5'))\n",
        "residual_model.save(os.path.join(MODELS_DIR, 'residual_neural.h5'))\n",
        "meta_model.save(os.path.join(MODELS_DIR, 'meta_learner_neural.h5'))\n",
        "\n",
        "# Save gradient boosting base models using joblib (scikit-learn compatible format)\n",
        "joblib.dump({\n",
        "    'xgb_deep': xgb_deep,\n",
        "    'xgb_shallow': xgb_shallow,\n",
        "    'lgbm_fast': lgbm_fast,\n",
        "    'catboost_robust': catboost_robust\n",
        "}, os.path.join(MODELS_DIR, 'ensemble_base_models_neural.joblib'))\n",
        "\n",
        "print('Saved all model results and artifacts')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "final_last",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
