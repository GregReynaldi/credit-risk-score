{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68003a35",
   "metadata": {},
   "source": [
    "## Model Explainability Analysis\n",
    "\n",
    "This notebook generates comprehensive explanations for the ensemble model predictions.\n",
    "\n",
    "**Purpose**: Understand how the model makes predictions and which features are most important.\n",
    "\n",
    "**Explainability Methods**:\n",
    "1. **SHAP (SHapley Additive exPlanations)**: \n",
    "   - Game theory-based feature importance\n",
    "   - Shows how each feature contributes to each prediction\n",
    "   - Provides both global (overall) and local (per-instance) explanations\n",
    "\n",
    "2. **LIME (Local Interpretable Model-agnostic Explanations)**:\n",
    "   - Approximates the model locally around a prediction\n",
    "   - Fast and interpretable for single predictions\n",
    "   - Shows which features push prediction up or down\n",
    "\n",
    "3. **Combined Analysis**:\n",
    "   - Merges SHAP and LIME insights\n",
    "   - Identifies risk-increasing and risk-decreasing features\n",
    "   - Compares local explanations to global patterns\n",
    "\n",
    "**Output**: SHAP/LIME visualizations and importance rankings saved to `artifacts/04_shap_images/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea36499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import shap\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "ROOT = os.path.abspath(os.getcwd())\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(ROOT, '..'))\n",
    "\n",
    "MODELS_DIR = os.path.join(PROJECT_ROOT, 'models')\n",
    "DATASET_DIR = os.path.join(PROJECT_ROOT, 'dataset')\n",
    "ARTIFACTS_DIR = os.path.join(PROJECT_ROOT, 'artifacts')\n",
    "SHAP_IMAGES_DIR = os.path.join(ARTIFACTS_DIR, '04_shap_images')\n",
    "\n",
    "os.makedirs(SHAP_IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb306e",
   "metadata": {},
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1103572c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (26064, 17)\n",
      "Test data shape: (6517, 17)\n",
      "Number of features: 17\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_pickle(os.path.join(DATASET_DIR, 'X_train.pkl'))\n",
    "X_test = pd.read_pickle(os.path.join(DATASET_DIR, 'X_test.pkl'))\n",
    "y_test = pd.read_pickle(os.path.join(DATASET_DIR, 'y_test.pkl'))\n",
    "\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.iloc[:, 0]\n",
    "\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Number of features: {len(feature_names)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ab883",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73bb3706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiscale ensemble model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "base_models_dict = joblib.load(os.path.join(MODELS_DIR, 'ensemble_base_models_neural.joblib'))\n",
    "meta_model = keras.models.load_model(os.path.join(MODELS_DIR, 'meta_learner_neural.h5'), compile=False)\n",
    "neural_network_model = keras.models.load_model(os.path.join(MODELS_DIR, 'residual_neural.h5'), compile=False)\n",
    "\n",
    "xgb_deep = base_models_dict['xgb_deep']\n",
    "xgb_shallow = base_models_dict['xgb_shallow']\n",
    "lgbm_fast = base_models_dict['lgbm_fast']\n",
    "catboost_robust = base_models_dict['catboost_robust']\n",
    "\n",
    "print(\"Multiscale ensemble model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23d7dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines predictions from 5 base models using a meta-learner\n",
    "# Takes input features and returns final probability predictions\n",
    "# Parameters: X - input features (DataFrame or numpy array)\n",
    "# Returns: numpy array of probability predictions (0-1 range)\n",
    "def ensemble_predict(X):\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "    \n",
    "    pred_xgb_deep = xgb_deep.predict_proba(X)[:, 1]\n",
    "    pred_xgb_shallow = xgb_shallow.predict_proba(X)[:, 1]\n",
    "    pred_lgbm = lgbm_fast.predict_proba(X)[:, 1]\n",
    "    pred_catboost = catboost_robust.predict_proba(X)[:, 1]\n",
    "    pred_neural = neural_network_model.predict(X, verbose=0).ravel()\n",
    "    \n",
    "    base_preds = np.column_stack([pred_xgb_deep, pred_xgb_shallow, pred_lgbm, pred_catboost, pred_neural])\n",
    "    final_pred = meta_model.predict(base_preds, verbose=0).ravel()\n",
    "    \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd71ac8",
   "metadata": {},
   "source": [
    "## SHAP Global Explainability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8832b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_data = X_train.sample(n=min(200, len(X_train)), random_state=42).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda2b5f",
   "metadata": {},
   "source": [
    "### SHAP Explainer Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91a23ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PermutationExplainer: Shuffles features to measure marginal contribution\n",
    "# Uses background_data as reference distribution for feature absence\n",
    "shap_explainer = shap.Explainer(ensemble_predict, background_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c68865",
   "metadata": {},
   "source": [
    "### SHAP Values Computation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "560ac753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Conda\\envs\\final_last\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"d:\\Conda\\envs\\final_last\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"d:\\Conda\\envs\\final_last\\lib\\subprocess.py\", line 1515, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"d:\\Conda\\envs\\final_last\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xce in position 4: invalid continuation byte\n",
      "PermutationExplainer explainer: 101it [07:20,  4.40s/it]                         \n"
     ]
    }
   ],
   "source": [
    "# Sample test data for SHAP analysis (faster computation)\n",
    "test_sample_size = min(100, len(X_test))\n",
    "X_test_sample = X_test.iloc[:test_sample_size].values\n",
    "\n",
    "# Compute SHAP values: measures how each feature contributes to each prediction\n",
    "# Higher absolute SHAP value means the feature has more impact\n",
    "shap_values = shap_explainer(X_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c267eef",
   "metadata": {},
   "source": [
    "### SHAP Summary Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d72a3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, feature_names=feature_names, max_display=20, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SHAP_IMAGES_DIR, 'shap_summary_plot.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b9c01bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "shap.plots.bar(shap_values, max_display=20, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SHAP_IMAGES_DIR, 'shap_bar_plot.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a78f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "shap.plots.waterfall(shap_values[0], max_display=15, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SHAP_IMAGES_DIR, 'shap_waterfall_plot.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b10add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "shap.plots.beeswarm(shap_values, max_display=20, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SHAP_IMAGES_DIR, 'shap_beeswarm_plot.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2198045b",
   "metadata": {},
   "source": [
    "### SHAP Feature Importance Ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abaaca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature  importance\n",
      "5           loan_percent_income    0.082715\n",
      "7                    loan_grade    0.076841\n",
      "1                 person_income    0.046387\n",
      "10   person_home_ownership_RENT    0.041634\n",
      "15          loan_intent_VENTURE    0.040208\n",
      "3                     loan_amnt    0.028927\n",
      "12  loan_intent_HOMEIMPROVEMENT    0.018909\n",
      "14         loan_intent_PERSONAL    0.016583\n",
      "11        loan_intent_EDUCATION    0.016057\n",
      "2             person_emp_length    0.014057\n"
     ]
    }
   ],
   "source": [
    "# Calculate feature importance by averaging absolute SHAP values across all samples\n",
    "# Features with higher average absolute SHAP values are more important globally\n",
    "shap_importance = np.mean(np.abs(shap_values.values), axis=0)\n",
    "\n",
    "shap_feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': shap_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "shap_top_features = shap_feature_importance.head(10).to_dict('records')\n",
    "\n",
    "with open(os.path.join(SHAP_IMAGES_DIR, 'shap_feature_importance.json'), 'w') as f:\n",
    "    json.dump(shap_top_features, f, indent=2)\n",
    "\n",
    "print(shap_feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e5314f",
   "metadata": {},
   "source": [
    "## SHAP Interaction Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f592e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_interaction_features = shap_feature_importance.head(6)['feature'].tolist()\n",
    "\n",
    "# Compute feature interactions: measures how features work together\n",
    "# Interaction strength = average of (SHAP_i * SHAP_j) across all samples\n",
    "# Higher values mean features have stronger joint effects on predictions\n",
    "interaction_matrix = np.zeros((len(feature_names), len(feature_names)))\n",
    "for i in range(len(feature_names)):\n",
    "    for j in range(i+1, len(feature_names)):\n",
    "        interaction_strength = np.mean(np.abs(shap_values.values[:, i] * shap_values.values[:, j]))\n",
    "        interaction_matrix[i, j] = interaction_strength\n",
    "        interaction_matrix[j, i] = interaction_strength"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f9f521",
   "metadata": {},
   "source": [
    "### Interaction Heatmap Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd352613",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_df = pd.DataFrame(\n",
    "    interaction_matrix,\n",
    "    index=feature_names,\n",
    "    columns=feature_names\n",
    ")\n",
    "\n",
    "top_interaction_subset = interaction_df.loc[top_interaction_features, top_interaction_features]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(top_interaction_subset, annot=True, fmt='.4f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={'label': 'Interaction Strength'})\n",
    "plt.title('SHAP Feature Interaction Matrix (Top 6 Features)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SHAP_IMAGES_DIR, 'shap_interaction_heatmap.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b607801",
   "metadata": {},
   "source": [
    "## Partial Dependence Plots (PDP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f326823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial Dependence Plots: show how changing one feature affects predictions\n",
    "# while keeping all other features at their original values\n",
    "pdp_features = shap_feature_importance.head(6)['feature'].tolist()\n",
    "pdp_indices = [feature_names.index(f) for f in pdp_features]\n",
    "\n",
    "pdp_sample = background_data[:100]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (feat_name, feat_idx) in enumerate(zip(pdp_features, pdp_indices)):\n",
    "    # Create range of feature values from 5th to 95th percentile\n",
    "    feature_values = np.linspace(\n",
    "        np.percentile(pdp_sample[:, feat_idx], 5),\n",
    "        np.percentile(pdp_sample[:, feat_idx], 95),\n",
    "        50\n",
    "    )\n",
    "    \n",
    "    # For each value, set feature to that value and get average prediction\n",
    "    pdp_values = []\n",
    "    for val in feature_values:\n",
    "        X_pdp = pdp_sample.copy()\n",
    "        X_pdp[:, feat_idx] = val\n",
    "        predictions = ensemble_predict(X_pdp)\n",
    "        pdp_values.append(np.mean(predictions))\n",
    "    \n",
    "    axes[idx].plot(feature_values, pdp_values, linewidth=2.5, color='#2E86AB')\n",
    "    axes[idx].fill_between(feature_values, pdp_values, alpha=0.3, color='#2E86AB')\n",
    "    axes[idx].set_xlabel(feat_name, fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Predicted Probability', fontsize=11)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].set_title(f'PDP: {feat_name}', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Partial Dependence Plots - Top 6 Features', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SHAP_IMAGES_DIR, 'partial_dependence_plots.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e853c9a",
   "metadata": {},
   "source": [
    "## Counterfactual Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb540cf9",
   "metadata": {},
   "source": [
    "### Counterfactual Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25fef974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 counterfactual explanations\n"
     ]
    }
   ],
   "source": [
    "# Counterfactual explanations: find minimal changes to flip predictions\n",
    "# Shows \"what if\" scenarios - what features need to change to get different outcome\n",
    "counterfactual_samples = []\n",
    "cf_sample_indices = [0, 10, 20]\n",
    "\n",
    "for sample_idx in cf_sample_indices:\n",
    "    if sample_idx >= len(X_test_sample):\n",
    "        continue\n",
    "    \n",
    "    original = X_test_sample[sample_idx:sample_idx+1]\n",
    "    original_pred = ensemble_predict(original)[0]\n",
    "    \n",
    "    # Target: flip prediction (low risk -> high risk threshold, or vice versa)\n",
    "    target_pred = 0.5 if original_pred < 0.5 else 0.3\n",
    "    \n",
    "    counterfactual = original.copy()\n",
    "    # Modify top 3 most important features to push prediction toward target\n",
    "    top_features = shap_feature_importance.head(3)['feature'].tolist()\n",
    "    \n",
    "    changes = {}\n",
    "    for feat_name in top_features:\n",
    "        feat_idx = feature_names.index(feat_name)\n",
    "        original_val = original[0, feat_idx]\n",
    "        \n",
    "        # Change feature to extreme value (high or low) based on desired direction\n",
    "        feature_range = np.percentile(background_data[:, feat_idx], [10, 90])\n",
    "        if original_pred < 0.5:\n",
    "            new_val = feature_range[1]  # Increase risk\n",
    "        else:\n",
    "            new_val = feature_range[0]  # Decrease risk\n",
    "        \n",
    "        counterfactual[0, feat_idx] = new_val\n",
    "        changes[feat_name] = {'original': float(original_val), 'counterfactual': float(new_val)}\n",
    "    \n",
    "    cf_pred = ensemble_predict(counterfactual)[0]\n",
    "    \n",
    "    counterfactual_samples.append({\n",
    "        'sample_idx': sample_idx,\n",
    "        'original_pred': float(original_pred),\n",
    "        'counterfactual_pred': float(cf_pred),\n",
    "        'target_pred': float(target_pred),\n",
    "        'changes': changes\n",
    "    })\n",
    "\n",
    "with open(os.path.join(SHAP_IMAGES_DIR, 'counterfactual_explanations.json'), 'w') as f:\n",
    "    json.dump(counterfactual_samples, f, indent=2)\n",
    "\n",
    "print(f\"Generated {len(counterfactual_samples)} counterfactual explanations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf908896",
   "metadata": {},
   "source": [
    "### Counterfactual Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e70a51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if counterfactual_samples:\n",
    "    cf = counterfactual_samples[0]\n",
    "    features_changed = list(cf['changes'].keys())\n",
    "    original_vals = [cf['changes'][f]['original'] for f in features_changed]\n",
    "    cf_vals = [cf['changes'][f]['counterfactual'] for f in features_changed]\n",
    "    \n",
    "    x = np.arange(len(features_changed))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(x - width/2, original_vals, width, label='Original', alpha=0.8, color='#E63946')\n",
    "    ax.bar(x + width/2, cf_vals, width, label='Counterfactual', alpha=0.8, color='#06A77D')\n",
    "    \n",
    "    ax.set_xlabel('Features', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Feature Values', fontsize=12)\n",
    "    ax.set_title(f'Counterfactual Explanation\\nOriginal Pred: {cf[\"original_pred\"]:.3f} â†’ Counterfactual Pred: {cf[\"counterfactual_pred\"]:.3f}', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(features_changed, rotation=45, ha='right')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(SHAP_IMAGES_DIR, 'counterfactual_visualization.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af62fa87",
   "metadata": {},
   "source": [
    "## Feature Dependency Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdeea23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dep_features = shap_feature_importance.head(5)['feature'].tolist()\n",
    "dependency_matrix = np.corrcoef(X_train[top_dep_features].T)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(dependency_matrix, annot=True, fmt='.3f', cmap='RdYlBu_r', center=0,\n",
    "            xticklabels=top_dep_features, yticklabels=top_dep_features,\n",
    "            square=True, linewidths=1, cbar_kws={'label': 'Correlation'}, ax=ax)\n",
    "ax.set_title('Feature Dependency Matrix (Top 5 Features)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SHAP_IMAGES_DIR, 'feature_dependency_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2209306c",
   "metadata": {},
   "source": [
    "## LIME Local Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "339f4325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function for LIME: converts probability output to class probabilities format\n",
    "# LIME needs probabilities for both classes (class 0 and class 1)\n",
    "def ensemble_predict_for_lime(X):\n",
    "    prob_class1 = ensemble_predict(X)\n",
    "    prob_class0 = 1 - prob_class1\n",
    "    return np.column_stack([prob_class0, prob_class1])\n",
    "\n",
    "# LIME explainer: creates local explanations by training simple model around each prediction\n",
    "# Uses training data to understand feature distributions\n",
    "lime_explainer = LimeTabularExplainer(\n",
    "    X_train.values,\n",
    "    feature_names=feature_names,\n",
    "    mode='classification',\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d07fc",
   "metadata": {},
   "source": [
    "### LIME Explanations Computation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49ff8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LIME explanations for multiple test samples\n",
    "# LIME gives local explanations showing which features push prediction up or down\n",
    "lime_explanations = []\n",
    "lime_importance_scores = np.zeros(len(feature_names))\n",
    "num_samples = min(50, len(X_test))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Get LIME explanation for this instance\n",
    "    explanation = lime_explainer.explain_instance(\n",
    "        X_test.iloc[i].values,\n",
    "        ensemble_predict_for_lime,\n",
    "        num_features=len(feature_names)\n",
    "    )\n",
    "    lime_explanations.append(explanation)\n",
    "    \n",
    "    # Extract feature importance from LIME explanation\n",
    "    # LIME returns conditions like \"feature_name <= value\" with importance scores\n",
    "    exp_list = explanation.as_list()\n",
    "    for item in exp_list:\n",
    "        condition_string, importance = item\n",
    "        \n",
    "        # Parse feature name from condition string (handles various operators)\n",
    "        if isinstance(condition_string, str):\n",
    "            extracted_feature_name = None\n",
    "            \n",
    "            if condition_string in feature_names:\n",
    "                extracted_feature_name = condition_string\n",
    "            else:\n",
    "                # Extract feature name from conditions like \"feature <= value\"\n",
    "                operators = [' <= ', ' >= ', ' > ', ' < ', ' == ', ' != ']\n",
    "                for op in operators:\n",
    "                    if op in condition_string:\n",
    "                        parts = condition_string.split(op, 1)\n",
    "                        if len(parts) > 0:\n",
    "                            potential_name = parts[0].strip()\n",
    "                            if potential_name in feature_names:\n",
    "                                extracted_feature_name = potential_name\n",
    "                                break\n",
    "                \n",
    "                # Handle nested conditions\n",
    "                if not extracted_feature_name and ' < ' in condition_string and ' <= ' in condition_string:\n",
    "                    parts = condition_string.split(' < ')\n",
    "                    if len(parts) >= 2 and ' <= ' in parts[1]:\n",
    "                        potential_name = parts[1].split(' <= ')[0].strip()\n",
    "                        if potential_name in feature_names:\n",
    "                            extracted_feature_name = potential_name\n",
    "            \n",
    "            # Accumulate importance scores across all samples\n",
    "            if extracted_feature_name:\n",
    "                feature_idx_num = feature_names.index(extracted_feature_name)\n",
    "                lime_importance_scores[feature_idx_num] += abs(importance)\n",
    "\n",
    "# Average importance across all samples\n",
    "if num_samples > 0:\n",
    "    lime_importance_scores = lime_importance_scores / num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb675b3e",
   "metadata": {},
   "source": [
    "### LIME Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c92c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = lime_explanations[0].as_pyplot_figure()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SHAP_IMAGES_DIR, 'lime_explanation_plot.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be92f98d",
   "metadata": {},
   "source": [
    "### LIME Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edf78403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature  importance\n",
      "9     person_home_ownership_OWN    0.157923\n",
      "15          loan_intent_VENTURE    0.123223\n",
      "5           loan_percent_income    0.119924\n",
      "7                    loan_grade    0.108267\n",
      "10   person_home_ownership_RENT    0.102286\n",
      "12  loan_intent_HOMEIMPROVEMENT    0.080422\n",
      "11        loan_intent_EDUCATION    0.069892\n",
      "1                 person_income    0.067300\n",
      "14         loan_intent_PERSONAL    0.053458\n",
      "8   person_home_ownership_OTHER    0.052252\n"
     ]
    }
   ],
   "source": [
    "lime_feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': lime_importance_scores\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "lime_top_features = lime_feature_importance.head(10).to_dict('records')\n",
    "\n",
    "with open(os.path.join(SHAP_IMAGES_DIR, 'lime_feature_importance.json'), 'w') as f:\n",
    "    json.dump(lime_top_features, f, indent=2)\n",
    "\n",
    "print(lime_feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eaee62",
   "metadata": {},
   "source": [
    "## Combined SHAP + LIME Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911fe015",
   "metadata": {},
   "source": [
    "### Combined Importance Calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90bf105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize SHAP and LIME importances to 0-1 range for fair comparison\n",
    "# Then average them to get combined importance score\n",
    "shap_normalized = shap_importance / (shap_importance.max() + 1e-9)\n",
    "lime_max = lime_importance_scores.max()\n",
    "lime_normalized = lime_importance_scores / (lime_max + 1e-9) if lime_max > 1e-9 else np.zeros_like(lime_importance_scores)\n",
    "\n",
    "# Combined importance: average of normalized SHAP and LIME scores\n",
    "# This gives more robust feature ranking by combining global (SHAP) and local (LIME) perspectives\n",
    "combined_importance = (shap_normalized + lime_normalized) / 2\n",
    "\n",
    "combined_feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'shap_importance': shap_normalized,\n",
    "    'lime_importance': lime_normalized,\n",
    "    'combined_importance': combined_importance\n",
    "}).sort_values('combined_importance', ascending=False)\n",
    "\n",
    "combined_top_features = combined_feature_importance.head(10).to_dict('records')\n",
    "\n",
    "with open(os.path.join(SHAP_IMAGES_DIR, 'combined_feature_importance.json'), 'w') as f:\n",
    "    json.dump(combined_top_features, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41411e4e",
   "metadata": {},
   "source": [
    "### Combined Importance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d68eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 15\n",
    "top_features = combined_feature_importance.head(top_n)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "x = np.arange(len(top_features))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, top_features['shap_importance'], width, label='SHAP', alpha=0.85, color='#E63946')\n",
    "ax.bar(x, top_features['lime_importance'], width, label='LIME', alpha=0.85, color='#F77F00')\n",
    "ax.bar(x + width, top_features['combined_importance'], width, label='Combined', alpha=0.85, color='#2E86AB')\n",
    "\n",
    "ax.set_xlabel('Features', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Normalized Importance', fontsize=13, fontweight='bold')\n",
    "ax.set_title('SHAP vs LIME vs Combined Feature Importance', fontsize=15, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(top_features['feature'], rotation=45, ha='right', fontsize=10)\n",
    "ax.legend(fontsize=12, loc='upper right')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SHAP_IMAGES_DIR, 'combined_importance_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08085d60",
   "metadata": {},
   "source": [
    "### Expected Calibration Score (ECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6704f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_values = y_test.values if hasattr(y_test, 'values') else y_test\n",
    "if isinstance(y_test_values, pd.Series):\n",
    "    y_test_values = y_test_values.values\n",
    "\n",
    "X_test_values = X_test.values if isinstance(X_test, pd.DataFrame) else X_test\n",
    "\n",
    "validation_sample_size = min(500, len(X_test_values))\n",
    "X_val_sample = X_test_values[:validation_sample_size]\n",
    "y_val_sample = y_test_values[:validation_sample_size]\n",
    "\n",
    "y_pred_proba = ensemble_predict(X_val_sample)\n",
    "\n",
    "# Expected Calibration Score: measures if predicted probabilities match actual frequencies\n",
    "# Well-calibrated model: when it predicts 70% risk, actual risk should be close to 70%\n",
    "# Lower ECS = better calibration\n",
    "n_bins = 10\n",
    "bins = np.linspace(0, 1, n_bins + 1)\n",
    "bin_indices = np.digitize(y_pred_proba, bins) - 1\n",
    "bin_indices = np.clip(bin_indices, 0, n_bins - 1)\n",
    "\n",
    "ecs_per_bin = []\n",
    "bin_counts = []\n",
    "bin_accuracies = []\n",
    "bin_confidences = []\n",
    "\n",
    "# For each bin, compare average predicted probability vs actual accuracy\n",
    "for i in range(n_bins):\n",
    "    bin_mask = bin_indices == i\n",
    "    bin_count = np.sum(bin_mask)\n",
    "    \n",
    "    if bin_count > 0:\n",
    "        bin_acc = np.mean(y_val_sample[bin_mask])  # Actual accuracy in this bin\n",
    "        bin_conf = np.mean(y_pred_proba[bin_mask])  # Average predicted probability\n",
    "        bin_error = np.abs(bin_acc - bin_conf)  # Calibration error for this bin\n",
    "        \n",
    "        ecs_per_bin.append(bin_error)\n",
    "        bin_counts.append(bin_count)\n",
    "        bin_accuracies.append(bin_acc)\n",
    "        bin_confidences.append(bin_conf)\n",
    "    else:\n",
    "        ecs_per_bin.append(0.0)\n",
    "        bin_counts.append(0)\n",
    "        bin_accuracies.append(0.0)\n",
    "        bin_confidences.append(0.0)\n",
    "\n",
    "# Weighted ECS: average error weighted by bin size (more samples = more weight)\n",
    "# Unweighted ECS: simple average of non-empty bins\n",
    "ecs_weighted = np.sum([ecs * count for ecs, count in zip(ecs_per_bin, bin_counts)]) / validation_sample_size\n",
    "ecs_unweighted = np.mean([ecs for ecs, count in zip(ecs_per_bin, bin_counts) if count > 0]) if any(bin_counts) else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c032bb0",
   "metadata": {},
   "source": [
    "### Calibration Curve Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384fa5c5",
   "metadata": {},
   "source": [
    "### Data Perturbation Distance (DPD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b010675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Perturbation Distance: tests model robustness to small input changes\n",
    "# Adds small random noise to inputs and measures how much predictions change\n",
    "# Lower DPD = more stable model (predictions don't change much with small input changes)\n",
    "perturbation_strength = 0.01  # 1% noise level\n",
    "n_perturbations = 10\n",
    "\n",
    "dpd_sample_size = min(100, len(X_val_sample))\n",
    "X_dpd_original = X_val_sample[:dpd_sample_size]\n",
    "\n",
    "original_predictions = ensemble_predict(X_dpd_original)\n",
    "perturbation_differences = []\n",
    "\n",
    "# Run multiple perturbations and average results\n",
    "for _ in range(n_perturbations):\n",
    "    noise = np.random.normal(0, perturbation_strength, X_dpd_original.shape)\n",
    "    X_perturbed = X_dpd_original + noise\n",
    "    perturbed_predictions = ensemble_predict(X_perturbed)\n",
    "    differences = np.abs(original_predictions - perturbed_predictions)\n",
    "    perturbation_differences.append(differences)\n",
    "\n",
    "# Compute statistics: mean, std, and max prediction change\n",
    "mean_differences = np.mean(perturbation_differences, axis=0)\n",
    "dpd_mean = np.mean(mean_differences)\n",
    "dpd_std = np.std(mean_differences)\n",
    "dpd_max = np.max(mean_differences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e55838",
   "metadata": {},
   "source": [
    "### Equalized Odds Difference (EOD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50d76d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equalized Odds Difference: measures fairness across different groups\n",
    "# Fair model should have similar true positive rates (TPR) and false positive rates (FPR) for all groups\n",
    "# Lower EOD = more fair (groups treated similarly)\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Define sensitive attributes (groups to compare fairness across)\n",
    "sensitive_attributes = {}\n",
    "\n",
    "loan_grade_features = [f for f in feature_names if 'loan_grade' in f.lower()]\n",
    "if loan_grade_features:\n",
    "    for grade_feat in loan_grade_features[:5]:\n",
    "        if grade_feat in X_test.columns:\n",
    "            grade_mask = X_test.iloc[:validation_sample_size][grade_feat].values > 0.5\n",
    "            if np.sum(grade_mask) > 10 and np.sum(~grade_mask) > 10:\n",
    "                sensitive_attributes[f\"has_{grade_feat}\"] = grade_mask\n",
    "\n",
    "person_income_median = np.median(X_test['person_income'].values[:validation_sample_size]) if 'person_income' in X_test.columns else None\n",
    "if person_income_median is not None:\n",
    "    income_high = X_test['person_income'].values[:validation_sample_size] >= person_income_median\n",
    "    if np.sum(income_high) > 10 and np.sum(~income_high) > 10:\n",
    "        sensitive_attributes[\"high_income\"] = income_high\n",
    "\n",
    "loan_percent_income_median = np.median(X_test['loan_percent_income'].values[:validation_sample_size]) if 'loan_percent_income' in X_test.columns else None\n",
    "if loan_percent_income_median is not None:\n",
    "    debt_ratio_low = X_test['loan_percent_income'].values[:validation_sample_size] < loan_percent_income_median\n",
    "    if np.sum(debt_ratio_low) > 10 and np.sum(~debt_ratio_low) > 10:\n",
    "        sensitive_attributes[\"low_debt_ratio\"] = debt_ratio_low\n",
    "\n",
    "eod_results = {}\n",
    "\n",
    "# For each sensitive attribute, compare TPR and FPR between groups\n",
    "for attr_name, attr_mask in sensitive_attributes.items():\n",
    "    group_0_mask = ~attr_mask\n",
    "    group_1_mask = attr_mask\n",
    "    \n",
    "    y_true_group_0 = y_val_sample[group_0_mask]\n",
    "    y_pred_group_0 = y_pred_binary[group_0_mask]\n",
    "    y_true_group_1 = y_val_sample[group_1_mask]\n",
    "    y_pred_group_1 = y_pred_binary[group_1_mask]\n",
    "    \n",
    "    # Compute confusion matrix for both groups\n",
    "    tn_0 = np.sum((y_true_group_0 == 0) & (y_pred_group_0 == 0))\n",
    "    fp_0 = np.sum((y_true_group_0 == 0) & (y_pred_group_0 == 1))\n",
    "    fn_0 = np.sum((y_true_group_0 == 1) & (y_pred_group_0 == 0))\n",
    "    tp_0 = np.sum((y_true_group_0 == 1) & (y_pred_group_0 == 1))\n",
    "    \n",
    "    tn_1 = np.sum((y_true_group_1 == 0) & (y_pred_group_1 == 0))\n",
    "    fp_1 = np.sum((y_true_group_1 == 0) & (y_pred_group_1 == 1))\n",
    "    fn_1 = np.sum((y_true_group_1 == 1) & (y_pred_group_1 == 0))\n",
    "    tp_1 = np.sum((y_true_group_1 == 1) & (y_pred_group_1 == 1))\n",
    "    \n",
    "    # Calculate TPR (recall) and FPR for each group\n",
    "    tpr_0 = tp_0 / (tp_0 + fn_0) if (tp_0 + fn_0) > 0 else 0.0\n",
    "    fpr_0 = fp_0 / (fp_0 + tn_0) if (fp_0 + tn_0) > 0 else 0.0\n",
    "    \n",
    "    tpr_1 = tp_1 / (tp_1 + fn_1) if (tp_1 + fn_1) > 0 else 0.0\n",
    "    fpr_1 = fp_1 / (fp_1 + tn_1) if (fp_1 + tn_1) > 0 else 0.0\n",
    "    \n",
    "    # EOD = maximum difference in TPR or FPR between groups\n",
    "    tpr_diff = abs(tpr_1 - tpr_0)\n",
    "    fpr_diff = abs(fpr_1 - fpr_0)\n",
    "    eod = max(tpr_diff, fpr_diff)\n",
    "    \n",
    "    eod_results[attr_name] = {\n",
    "        'eod': float(eod),\n",
    "        'tpr_diff': float(tpr_diff),\n",
    "        'fpr_diff': float(fpr_diff),\n",
    "        'tpr_group_0': float(tpr_0),\n",
    "        'tpr_group_1': float(tpr_1),\n",
    "        'fpr_group_0': float(fpr_0),\n",
    "        'fpr_group_1': float(fpr_1),\n",
    "        'group_0_size': int(np.sum(group_0_mask)),\n",
    "        'group_1_size': int(np.sum(group_1_mask))\n",
    "    }\n",
    "\n",
    "overall_eod = np.mean([result['eod'] for result in eod_results.values()]) if eod_results else 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c265ec7",
   "metadata": {},
   "source": [
    "## Results Summary and Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c396898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(SHAP_IMAGES_DIR, 'shap_values.pkl'), 'wb') as f:\n",
    "    pickle.dump(shap_values.values, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed670a",
   "metadata": {},
   "source": [
    "### Comprehensive Research Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9952c5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Report Summary:\n",
      "  ECS (Weighted): 0.117146\n",
      "  DPD (Mean): 0.077951\n",
      "  EOD (Overall): 0.064004\n",
      "  Top SHAP Feature: loan_percent_income\n",
      "  Top LIME Feature: person_home_ownership_OWN\n",
      "  Counterfactuals Generated: 3\n",
      "\n",
      "All results saved to artifacts directory\n"
     ]
    }
   ],
   "source": [
    "research_report = {\n",
    "    'timestamp': pd.Timestamp.now().isoformat(),\n",
    "    'sample_sizes': {\n",
    "        'shap_analysis': int(test_sample_size),\n",
    "        'lime_analysis': int(num_samples),\n",
    "        'validation_metrics': int(validation_sample_size)\n",
    "    },\n",
    "    'feature_importance': {\n",
    "        'shap_top_10': shap_top_features,\n",
    "        'lime_top_10': lime_top_features,\n",
    "        'combined_top_10': combined_top_features\n",
    "    },\n",
    "    'validation_metrics': {\n",
    "        'expected_calibration_score': {\n",
    "            'ecs_weighted': float(ecs_weighted),\n",
    "            'ecs_unweighted': float(ecs_unweighted),\n",
    "            'n_bins': int(n_bins)\n",
    "        },\n",
    "        'data_perturbation_distance': {\n",
    "            'dpd_mean': float(dpd_mean),\n",
    "            'dpd_std': float(dpd_std),\n",
    "            'dpd_max': float(dpd_max),\n",
    "            'perturbation_strength': float(perturbation_strength),\n",
    "            'n_perturbations': int(n_perturbations)\n",
    "        },\n",
    "        'equalized_odds_difference': {\n",
    "            'overall_eod': float(overall_eod),\n",
    "            'attributes': eod_results\n",
    "        }\n",
    "    },\n",
    "    'counterfactual_explanations': {\n",
    "        'num_samples': len(counterfactual_samples),\n",
    "        'samples': counterfactual_samples\n",
    "    },\n",
    "    'interpretation_guidelines': {\n",
    "        'ecs': 'Lower is better. ECS < 0.05 indicates good calibration.',\n",
    "        'dpd': 'Lower is better. DPD < 0.05 indicates good stability to perturbations.',\n",
    "        'eod': 'Lower is better. EOD < 0.1 indicates acceptable fairness.'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(SHAP_IMAGES_DIR, 'comprehensive_research_report.json'), 'w') as f:\n",
    "    json.dump(research_report, f, indent=2)\n",
    "\n",
    "print(\"Research Report Summary:\")\n",
    "print(f\"  ECS (Weighted): {ecs_weighted:.6f}\")\n",
    "print(f\"  DPD (Mean): {dpd_mean:.6f}\")\n",
    "print(f\"  EOD (Overall): {overall_eod:.6f}\")\n",
    "print(f\"  Top SHAP Feature: {shap_feature_importance.iloc[0]['feature']}\")\n",
    "print(f\"  Top LIME Feature: {lime_feature_importance.iloc[0]['feature']}\")\n",
    "print(f\"  Counterfactuals Generated: {len(counterfactual_samples)}\")\n",
    "print(\"\\nAll results saved to artifacts directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f66e3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 7))\n",
    "\n",
    "bin_centers = [(bins[i] + bins[i+1]) / 2 for i in range(n_bins)]\n",
    "non_zero_bins = [i for i, count in enumerate(bin_counts) if count > 0]\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration', linewidth=2.5, alpha=0.7)\n",
    "ax.plot([bin_centers[i] for i in non_zero_bins], \n",
    "        [bin_accuracies[i] for i in non_zero_bins], \n",
    "        'o-', label='Model Calibration', linewidth=3, markersize=10, color='#2E86AB')\n",
    "\n",
    "for i in non_zero_bins:\n",
    "    if bin_counts[i] > 0:\n",
    "        ax.bar(bin_centers[i], bin_accuracies[i], width=0.08, alpha=0.25, color='#2E86AB')\n",
    "\n",
    "ax.set_xlabel('Mean Predicted Probability (Confidence)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Mean Actual Accuracy', fontsize=13, fontweight='bold')\n",
    "ax.set_title(f'Calibration Curve (ECS = {ecs_weighted:.4f})', fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=12, loc='upper left')\n",
    "ax.grid(alpha=0.3, linestyle='--')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SHAP_IMAGES_DIR, 'calibration_curve.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_last",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
